"""
Utils to create a synthetic dataset to train generative models with.

The section is split in two parts:
- 1) **TimeSeries Dataset** Generation of a gwpy TimeSeries dataset
    making use of random noise and sinusoidal functions
- 2) **Q-plot Dataset** Conversion of TimeSeries dataset into 2D
    Image dataset making use of q_transform

The dataset used to train the NN with is created as a 2D images. Note that
you do not need to run the two sections each time, but can rather save
the dataset after creating it once and loading it at the beginning of
Process Data that to save time.
"""

import multiprocessing

import matplotlib.pyplot as plt
import matplotlib.transforms as mtrans
import numpy as np
import pandas as pd
from gwpy.timeseries import TimeSeries


def _get_rng(random_state=None):
    """Return a numpy Generator, given None, int, or Generator."""
    if isinstance(random_state, np.random.Generator):
        return random_state
    return np.random.default_rng(random_state)


def generate_dataset_aux_channels(
        rows,
        columns,
        duration=10,
        sample_rate=500,
        num_waves_range=(10, 15),
        noise_amplitude=0.1,
        random_state=None,
):
    """Generate a Pandas DataFrame with randomly generated smooth sine wave
    time series with added smooth random noise.

    Parameters:
        - rows (int): Number of rows in the DataFrame.
        - columns (int): Number of columns in the DataFrame.
        - duration (float): Duration of the time series data in seconds
            (default is 10 seconds).
        - sample_rate (int): Sampling rate of the time series data in samples
            per second (default is 500 samples per second).
        - num_waves_range (tuple): Range for the random number of sine waves
            to be generated for each time series.
            Format: (min_num_waves, max_num_waves) (default is (10, 15)),
            upper bound is exclusive as in numpy.randint.
        - noise_amplitude (float): Amplitude of the smooth random noise added
            to the time series data (default is 0.1).
        - random_state (None | int | np.random.Generator): Random seed or
            Generator for reproducibility.

    Returns:
        - DataFrame: Pandas DataFrame containing the generated time series
            data.
    """
    rng = _get_rng(random_state)

    # Generate time array
    n_samples = int(duration * sample_rate)
    times = np.linspace(0, duration, n_samples, endpoint=False)
    dt = 1.0 / sample_rate

    dfs = []
    for _ in range(rows):
        df_dict = {}
        for col in range(columns):
            wave_data = np.zeros_like(times)

            # Random number of sine waves, high is exclusive to match original
            num_waves = rng.integers(num_waves_range[0], num_waves_range[1])

            # Generate each sine wave
            for _ in range(num_waves):
                amplitude = rng.uniform(0.5, 2.0)
                frequency = rng.uniform(0.5, 5.0)
                phase = rng.uniform(0, 2 * np.pi)

                wave_data += amplitude * np.sin(
                    2 * np.pi * frequency * times + phase
                )

            # Add smooth random noise to the wave data
            smooth_noise = rng.normal(0.0, noise_amplitude, size=wave_data.shape)
            wave_data += smooth_noise

            ts = TimeSeries(wave_data, t0=0, dt=dt)
            df_dict[f'Aux_{col + 1}'] = [ts]

        df_row = pd.DataFrame(df_dict)
        dfs.append(df_row)

    df = pd.concat(dfs, ignore_index=True, axis=0)
    return df


def generate_dataset_main_channel(
        input_df,
        weights=None,
        noise_amplitude=0.1,
        random_state=None,
):
    """Generate a dataset where each row of a single column is a weighted linear
    combination of the entries in the corresponding row in the input DataFrame
    plus random noise.

    Parameters:
        - input_df (DataFrame): Input DataFrame generated by
            ``generate_dataset_aux_channels``.
        - weights (array-like): Optional weights for each entry in the row.
            If None, random weights are generated (default is None).
            Weights are drawn uniformly in [0.5, 1.5).
        - noise_amplitude (float): Standard deviation of the random noise added
            to the linear combination (default is 0.1).
        - random_state (None | int | np.random.Generator): Random seed or
            Generator for reproducibility (used for weights and noise).

    Returns:
        - DataFrame: Pandas DataFrame containing the generated linear
            combination dataset.
    """
    rng = _get_rng(random_state)

    dt = input_df.iloc[0, 0].dt

    # Generate random weights if not provided
    if weights is None:
        n_cols = len(input_df.columns)
        # randomly generate weights in range [0.5, 1.5)
        weights = rng.random(n_cols) + 0.5
    else:
        weights = np.asarray(weights, dtype=float)
    # print(weights)  # removed: avoid side-effects in library code

    linear_combination_data = []

    # Iterate over rows of the input DataFrame
    for _, row in input_df.iterrows():
        # row is a Series of TimeSeries; broadcasting with weights works elementwise
        linear_combination = np.sum(row * weights)

        # Add scalar random noise to the TimeSeries
        noise = rng.normal(0.0, noise_amplitude)
        linear_combination += noise

        # linear_combination is already a TimeSeries; no need to wrap again
        linear_combination_data.append([linear_combination])

    linear_combination_df = pd.DataFrame(
        linear_combination_data, columns=['Main']
    )
    return linear_combination_df


def extract_peak_frequency(hq):
    """Calculates peak frequency (and relative time) of a given qplot

    Input:
    - hq (gwpy.Spectrogram) : Qtransform

    Return:
    - index_time (int) : time index in qtransform relative to peak frequency
    - index_freq (int) : frequency index in qtransform relative to peak frequency
    """
    index_flat = np.argmax(hq.value)
    index_time, index_freq = np.unravel_index(index_flat, hq.shape)
    return index_time, index_freq


def cut_image(qplot_array, index_freq, index_time, square_size=64):
    """Cut qplot as square_size X square_size 2D np.array centered at peak
    frequency and corresponding time

    Input:
    - qplot_array (np.array) : qplot relative to the whole TimeSeries
    - index_time (int) : time index in qtransform relative to peak frequency
    - index_freq (int) : frequency index in qtransorm relative to peak
        frequency
    - square_size (int) : Size in pixels of qplot image (default 64)

    Return:
    - subarray (np.array) : qplot cut as square_size X square_size np.array
    """

    center_x = index_time
    center_y = index_freq

    original_width, original_height = qplot_array.shape

    start_x = max(center_x - square_size // 2, 0)
    end_x = min(start_x + square_size, original_width)
    start_y = max(center_y - square_size // 2, 0)
    end_y = min(start_y + square_size, original_height)

    # Adjust indices if needed to make sure the resulting subarray is
    # (square_size X square_size)
    if end_x - start_x < square_size:
        diff_x = square_size - (end_x - start_x)
        if end_x < original_width:
            end_x = min(original_width, end_x + diff_x)
        else:
            start_x = max(0, start_x - diff_x)

    if end_y - start_y < square_size:
        diff_y = square_size - (end_y - start_y)
        if end_y < original_height:
            end_y = min(original_height, end_y + diff_y)
        else:
            start_y = max(0, start_y - diff_y)

    subarray = qplot_array[start_x:end_x, start_y:end_y]
    return subarray


def process_image(row, row_idx, channels, square_size):
    """Processes df's row to generate qplot images

    Input:
    - row (pd.Series) : row of TimeSeries Dataframe
    - row_idx (int) : index relative to row in DataFrame (unused)
    - channels (list): Name of columns of DataFrame
    - square_size (int): Size in pixels of qplot image

    Return:
    df_row (DataFrame): Row containing qplot images as 2D np.array
    """
    df_row = pd.DataFrame(columns=channels)

    index_time = None
    index_freq = None

    for i, channel in enumerate(channels):
        qplot = row[channel].q_transform(frange=(10, 150))

        # calculate peak frequency and time indices for first (main) channel
        if i == 0:
            index_time, index_freq = extract_peak_frequency(qplot)

        qplot_array = qplot.value
        qplot_array_cut = cut_image(
            qplot_array, index_freq, index_time, square_size
        )
        df_row[channel] = [qplot_array_cut]

    return df_row


def generate_cut_image_dataset(df, channels, num_processes=20, square_size=128):
    """Generates qplot dataset taking pandas df containing main+aux channels as input.
    The output is a df containing qtransforms (frequency range 10-150Hz) in the form
    of square_size x square_size 2D np.array.

    Args:
        df (DataFrame): DataFrame containing Main and Aux channels' gwpy TimeSeries
            (Main channel is always first).
        channels (list): Name of columns in the DataFrame.
        num_processes (int): Number of cores for multiprocess (default 20).
        square_size (int): Size in pixels of qplot image.

    Returns:
        DataFrame: Pandas DataFrame containing the q_transform np.array data.
    """
    n_rows = df.shape[0]
    if n_rows == 0:
        # Return empty DataFrame with same columns
        return df.iloc[0:0].copy()

    # For small datasets or 1 row, multiprocessing overhead dominates
    if n_rows == 1 or num_processes == 1:
        results = [process_image(df.iloc[row], row, channels, square_size)
                   for row in range(n_rows)]
    else:
        effective_procs = min(num_processes, multiprocessing.cpu_count(), n_rows)
        args = [
            (df.iloc[row], row, channels, square_size)
            for row in range(n_rows)
        ]
        with multiprocessing.Pool(processes=effective_procs) as pool:
            results = pool.starmap(process_image, args)

    return pd.concat(results, ignore_index=True)


def show_dataset(df, size, num_plots=10):
    """Plots qtransforms for first 4 columns in given df

    Input:
    - df (DataFrame) : DataFrame containing qtransforms in the form of 2d
        np.array
    - size (int) : square size in pixels of qplots
    - num_plots (int) : number of rows of df to make the plot for (default 10)

    Return
    - nothing, it just displays plots
    """
    num_plots = min(num_plots, len(df))
    if num_plots == 0:
        return

    ch_list = list(df.columns)
    fig, axes = plt.subplots(2 * num_plots, 2, figsize=(18, 12 * num_plots))

    for j in range(num_plots):
        qplt_r = np.flipud(df.iloc[j, 0].T)
        qplt_aux1 = np.flipud(df.iloc[j, 1].T)
        qplt_aux2 = np.flipud(df.iloc[j, 2].T)
        qplt_aux3 = np.flipud(df.iloc[j, 3].T)

        im_r = axes[2 * j, 0].imshow(
            qplt_r, aspect='auto',
            extent=[0, size, 0, size], vmin=0, vmax=25
        )
        axes[2 * j, 0].set_title(ch_list[0])
        axes[2 * j, 0].set_xlabel('Time')
        axes[2 * j, 0].set_ylabel('Frequency')
        fig.colorbar(im_r, ax=axes[2 * j, 0])

        im_g = axes[2 * j, 1].imshow(
            qplt_aux1, aspect='auto',
            extent=[0, size, 0, size], vmin=0, vmax=25
        )
        axes[2 * j, 1].set_title(ch_list[1])
        axes[2 * j, 1].set_xlabel('Time')
        axes[2 * j, 1].set_ylabel('Frequency')
        fig.colorbar(im_g, ax=axes[2 * j, 1])

        im_g = axes[2 * j + 1, 0].imshow(
            qplt_aux2, aspect='auto',
            extent=[0, size, 0, size], vmin=0, vmax=25
        )
        axes[2 * j + 1, 0].set_title(ch_list[2])
        axes[2 * j + 1, 0].set_xlabel('Time')
        axes[2 * j + 1, 0].set_ylabel('Frequency')
        fig.colorbar(im_g, ax=axes[2 * j + 1, 0])

        im_g = axes[2 * j + 1, 1].imshow(
            qplt_aux3, aspect='auto',
            extent=[0, size, 0, size], vmin=0, vmax=25
        )
        axes[2 * j + 1, 1].set_title(ch_list[3])
        axes[2 * j + 1, 1].set_xlabel('Time')
        axes[2 * j + 1, 1].set_ylabel('Frequency')
        fig.colorbar(im_g, ax=axes[2 * j + 1, 1])

    # After all plots are created, compute and draw separators
    fig.canvas.draw()
    r = fig.canvas.get_renderer()

    def get_bbox(ax):
        return ax.get_tightbbox(r).transformed(fig.transFigure.inverted())

    bboxes = np.array(list(map(get_bbox, axes.flat)), mtrans.Bbox).reshape(axes.shape)

    ymax = np.array([b.y1 for b in bboxes.flat]).reshape(axes.shape).max(axis=1)
    ymin = np.array([b.y0 for b in bboxes.flat]).reshape(axes.shape).min(axis=1)
    ys = np.c_[ymax[1:], ymin[:-1]].mean(axis=1)

    for y in ys[1::2]:
        line = plt.Line2D(
            [0, 1], [y, y], transform=fig.transFigure, color="black"
        )
        fig.add_artist(line)

    plt.show()


def normalize_(data, chan=4):
    """Normalizes the qplot data to the range [0,1] for NN convergence purposes

    Input:
    - data (torch.Tensor) : dataset of qtransforms
    - chan (int) : number of channels in dataset (default 4)

    Return:
    - data (torch.tensor) : normalized dataset
    """
    # Compute the maximum value for each channel across all tensors
    max_vals = data.view(data.shape[0], data.shape[1], -1).max(0)[0].max(1)[0]
    print("Maximum values for each channel across all tensors:",
          max_vals, max_vals.shape)
    data /= max_vals.view(1, chan, 1, 1)
    return data
