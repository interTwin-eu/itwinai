
@misc{hython,
  author = {I. F. Ferrario et al.},
  title = {Hython},
  year = {2025},
  publisher = {GitHub},
  url = {https://github.com/interTwin-eu/hython}
  urldate = {2025-08-14},
}

@article{ray:2018,
      title={Ray: A Distributed Framework for Emerging AI Applications}, 
      author={Philipp Moritz and Robert Nishihara and Stephanie Wang and Alexey Tumanov and Richard Liaw and Eric Liang and Melih Elibol and Zongheng Yang and William Paul and Michael I. Jordan and Ion Stoica},
      year={2018},
      eprint={1712.05889},
      archivePrefix={arXiv},
      primaryClass={cs.DC},
      url={https://arxiv.org/abs/1712.05889}, 
}

@misc{intertwin_eu,
	title = {{interTwin} project},
	url = {https://www.intertwin.eu/},
	language = {en},
	urldate = {2025-02-27},
}

@misc{cmcc,
	title = {{CMCC} {Foundation}},
	url = {https://www.cmcc.it/},
	urldate = {2025-02-27},
}

@misc{eurac,
	title = {Eurac {Research}},
	url = {https://www.eurac.edu/en},
	abstract = {Eurac Research is a private research center​ based in Bozen-Bolzano. Our researchers come from a wide variety of scientific fields and all parts of the world.},
	language = {en},
	urldate = {2025-02-27},
}

@misc{interlink,
	title = {interLink},
	copyright = {Apache-2.0},
	url = {https://github.com/interLink-hq/interLink},
	abstract = {InterLink aims to provide an abstraction for the execution of a Kubernetes pod on any remote resource capable of managing a Container execution lifecycle},
	urldate = {2025-07-27},
	publisher = {interTwin Community},
	month = feb,
	year = {2025},
}

@article{benach_intertwin_2023,
	title = {{interTwin} {D3}.1 {DTE} blueprint architecture, functional specifications and requirements analysis first version},
	url = {https://zenodo.org/records/10417124},
	abstract = {This document provides an architectural blueprint for the interTwin Digital Twin Engine, outlining its functional specifications, requirements analysis, and fundamental building blocks.


The blueprint is designed to be utilised by the interTwin project's technical Work Packages (WPs) to align with the requirements of associated subsystems. Additionally, it considers other relevant initiatives and projects to identify potential architectural components that can be incorporated within the interTwin context. The blueprint will ultimately serve as a conceptual model of the Digital Twin Engine, following its planned evolution and iterations through collaborative co-creation during the project.},
	language = {eng},
	urldate = {2025-02-27},
	author = {Benach, Raul Bardaji and Manzi (EGI), Andrea and Rodero (EGI), Ivan},
	month = jun,
	year = {2023},
	note = {Publisher: Zenodo},
	keywords = {Architecture, Digital Twin Engine, functional specifications, requirements analysis},
}

@article{campos_intertwin_2023,
	title = {{interTwin} {D6}.2 {First} release of the {DTE} core modules},
	url = {https://zenodo.org/records/10224213},
	abstract = {The deliverable includes the status of the development and integration of all WP6 software products available with the first release.},
	language = {eng},
	urldate = {2025-02-27},
	author = {Campos, Isabel and Moltó, Germán and Jacob, Alexander and Orviz, Pablo and Caballer, Miguel and Bunino, Matteo and Zoechbauer, Alexander and Fiore, Sandro},
	month = nov,
	year = {2023},
	note = {Publisher: Zenodo},
	keywords = {Core, development, DTE, integration},
}

@misc{openeo,
	title = {{openEO}},
	url = {https://openeo.org/},
	urldate = {2025-04-24},
}

@Article{horovod,
  author  = {Sergeev, Alexander and Del Balso, Mike},
  journal = {arXiv:1802.05799},
  title   = {{Horovod: fast and easy distributed deep learning in TensorFlow}},
  year    = {2018},
  doi     = {10.48550/arXiv.1802.05799},
}

@InProceedings{deepspeed,
  author    = {Rasley, Jeff and Rajbhandari, Samyam and Ruwase, Olatunji and He, Yuxiong},
  booktitle = {Proc. 26th ACM SIGKDD International Conference on Knowledge Discovery \& Data Mining},
  title     = {{Deepspeed: System optimizations enable training deep learning models with over 100 billion parameters}},
  year      = {2020},
  pages     = {3505-3506},
  doi       = {10.1145/3394486.3406703},
}

@Article{torch_ddp,
  author  = {Li, Shen and Zhao, Yanli and Varma, Rohan and Salpekar, Omkar and Noordhuis, Pieter and Li, Teng and Paszke, Adam and Smith, Jeff and Vaughan, Brian and Damania, Pritam and others},
  journal = {arXiv:2006.15704},
  title   = {{Pytorch Distributed: Experiences on accelerating data parallel training}},
  year    = {2020},
  doi     = {10.48550/arXiv.2006.15704},
}

@misc{infn,
	title = {{Istituto} {Nazionale} di {Fisica} {Nucleare}},
	url = {https://www.infn.it/en/},
	abstract = {The INFN is the national public research body, supervised by the Ministry of Education, Universities and Research (MIUR), dedicated to the study of the fundamental constituents of matter and the laws that govern them. It conducts research, both theoretical and experimental, in the fields of subnuclear, nuclear and astroparticle physics.},
	language = {en},
	urldate = {2025-04-24},
}

@misc{upv,
	title = {{Universitat} {Politècnica} de {València}},
	url = {https://www.upv.es/},
	urldate = {2025-04-24},
}

@misc{ray_tune,
  title={Tune: A Research Platform for Distributed Model Selection and Training},
  author={Liaw, Richard and Liang, Eric and Nishihara, Robert and Moritz, Philipp and Gonzalez, Joseph E. and Stoica, Ion},
  year={2018},
  publisher={arXiv},
  eprint={1807.05118},
  archivePrefix={arXiv},
  commentedOut_doi={10.48550/ARXIV.1807.05118},
  keywords={Machine Learning (cs.LG), Distributed, Parallel, and Cluster Computing (cs.DC), Machine Learning (stat.ML), FOS: Computer and information sciences, FOS: Computer and information sciences},
  copyright={arXiv.org perpetual, non-exclusive license},
  commentedOut_note={Available at \url{https://arxiv.org/abs/1807.05118}}
}

@misc{mlflow,
	title = {{MLflow}I},
	url = {https://mlflow.org/},
	urldate = {2025-04-24},
}

@misc{unitrento,
	title = {{UniTrento}},
	url = {https://www.unitn.it/it},
	abstract = {Home page UniTrento {\textbar} Il sito web dell'Università degli Studi di Trento. Un'università europea in Italia.},
	language = {it},
	urldate = {2025-04-24},
	month = apr,
	year = {2025},
}

@misc{wandb,
	title = {Weights \& {Biases}},
	shorttitle = {Weights \& {Biases}},
	url = {https://wandb.ai/site/},
	abstract = {Weights \& Biases is the leading AI developer platform to train and fine-tune models, manage models from experimentation to production, and track and evaluate GenAI applications powered by LLMs.},
	language = {en-US},
	urldate = {2025-04-25},
}

@misc{tensorboard,
	title = {{TensorBoard}},
	url = {https://www.tensorflow.org/tensorboard},
	urldate = {2025-04-25},
}

@misc{yprovml,
	title = {{yProvML}},
	copyright = {GPL-3.0},
	url = {https://github.com/HPCI-Lab/yProvML},
	urldate = {2025-04-25},
	publisher = {HPCI-Lab},
	month = apr,
	year = {2025},
	note = {original-date: 2023-12-06T11:52:05Z},
}

@misc{py_spy,
	title = {{py-spy:} {Sampling} profiler for {Python} programs},
	url = {https://github.com/benfred/py-spy},
	urldate = {2025-07-30},
}

@misc{dagger,
	title = {Dagger.io},
	url = {https://dagger.io/},
	abstract = {Build powerful software environments and containerized operations from modular components and simple functions. Perfect for complex software delivery and AI agents. Built by the creators of Docker.},
	language = {en},
	urldate = {2025-07-30},
}

@misc{choosing_gh_runners,
	title = {GitHub hosted runners},
	url = {https://docs-internal.github.com/en/actions/how-tos/write-workflows/choose-where-workflows-run/choose-the-runner-for-a-job?utm_source=chatgpt.com},
	abstract = {Define the type of machine that will process a job in your workflow.},
	language = {en},
	urldate = {2025-07-30},
}

@article{JUWELS,
  title={{JUWELS:} Modular Tier-0/1 supercomputer at the {J{\"u}lich Supercomputing Centre}},
  author={Krause, Dorian},
  journal={J. of Large-Scale Research Facilities},
  volume={5},
  number={A135},
  year={2019},
  doi     = {10.17815/jlsrf-5-171},
}
