# Tutorial on itwinai TorchTrainer adapted for the distributed GAN using MNIST dataset

The code is adapted from [this example](https://github.com/pytorch/examples/blob/main/mnist/main.py) and a simple GAN model as the baseline that can be found in a file named `simpleGAN.py` in this directory.

## Setup

First, from the root of this repository, build the environment containing
pytorch, horovod and deepspeed. You can *try* with:

```bash
# Creates a Python venv called envAI_hdfml
make torch-gpu-jsc
```

Then navigate to the project working directory

```bash
# Creates a Python venv called envAI_hdfml
cd tutorials/distributed-ml/torch-tutorial-GAN
```

## Distributed training on a single node (interactive)

If you want to use SLURM in interactive mode, do the following:

```bash
# Allocate resources
$ salloc --partition=batch --nodes=1 --account=intertwin  --gres=gpu:4 --time=1:59:00
job ID is XXXX
# Get a shell in the compute node (if using SLURM)
$ srun --jobid XXXX --overlap --pty /bin/bash 
# Now you are inside the compute node

# On JSC, you may need to load some modules...
ml --force purge
ml Stages/2024 GCC OpenMPI CUDA/12 MPI-settings/CUDA Python HDF5 PnetCDF libaio mpi4py

# ...before activating the Python environment (adapt this to your env name/path)
source ../../../envAI_hdfml/bin/activate
```

To launch the training with torch DDP use:

```bash
torchrun --standalone --nnodes=1 --nproc-per-node=gpu train.py --strategy ddp

# Optional -- from a SLURM login node:
srun --jobid XXXX --ntasks-per-node=1 torchrun --standalone --nnodes=1 --nproc-per-node=gpu train.py --strategy ddp
```

To launch the training with Microsoft DeepSpeed use:

```bash
deepspeed train.py -s deepspeed --deepspeed

# Optional -- from a SLURM login node:
srun --jobid XXXX --ntasks-per-node=1 deepspeed train.py -s deepspeed --deepspeed 
```

To launch the training with Horovod use:

> [!NOTE]  
> NOTE: Assuming 4 GPUs are available.

If your setup has a different number of GPUs, change the `-np 4 -H localhost:4` part.

> [!WARNING]  
> To use `horovodrun`, make sure that `mpirun` is available in your environment. Otherwise
> you cannot use Horovod in interactive mode.

```bash
# Assuming 4 GPUs are available (-np=4)
horovodrun -np 4 -H localhost:4 train.py -s horovod

# Optional -- from a SLURM login node:
srun --jobid XXXX --ntasks-per-node=1 horovodrun -np 4 -H localhost:4 python -u train.py -s horovod
```

## Analyze the logs

Analyze the logs with MLFlow:

```bash
itwinai mlflow-ui --path mllogs/mlflow
```

# Distributed GAN Documentation

This Guide provides a detailed explanation of how a simple Generative Adversarial Network (GAN) has been adapted to operate within a distributed environment using the `GANTrainer`. This adaptation enables more efficient training on larger datasets by leveraging distributed computing resources.

## Overview

A Generative Adversarial Network consists of two key components:

- **Generator (G)**: Generates new data instances.
- **Discriminator (D)**: Evaluates them for authenticity, aiming to distinguish real instances from the fake ones generated by the Generator.

The training process involves iterative adjustments where the Generator tries to produce data indistinguishable from actual data, and the Discriminator improves its ability to detect fakes.

## Steps to make a distributed GAN model

### Step 1: Define Model Architecture

Both the Generator and Discriminator are defined using PyTorch's `nn.Module`. The specific architecture for both includes convolutional layers that are well-suited for processing image data.

#### Generator Architecture

Here we define a simple Generator architecture with 1 input and output layer plus 3 hidden layers.

```python
class Generator(nn.Module):
    def __init__(self):
        super(Generator, self).__init__()
        self.main = nn.Sequential(
            nn.ConvTranspose2d(Z_DIM, G_HIDDEN * 8, 4, 1, 0, bias=False),
            nn.BatchNorm2d(G_HIDDEN * 8),
            nn.ReLU(True),
            nn.ConvTranspose2d(G_HIDDEN * 8, G_HIDDEN * \
                               4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(G_HIDDEN * 4),
            nn.ReLU(True),
            nn.ConvTranspose2d(G_HIDDEN * 4, G_HIDDEN * \
                               2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(G_HIDDEN * 2),
            nn.ReLU(True),
            nn.ConvTranspose2d(G_HIDDEN * 2, G_HIDDEN, 4, 2, 1, bias=False),
            nn.BatchNorm2d(G_HIDDEN),
            nn.ReLU(True),
            nn.ConvTranspose2d(G_HIDDEN, IMAGE_CHANNEL, 4, 2, 1, bias=False),
            nn.Tanh()
        )

    def forward(self, input):
        return self.main(input)
```

#### Discriminator Architecture

Here we define a simple Discriminator architecture with 4 layers plus one output layer.

```python
class Discriminator(nn.Module):
    def __init__(self):
        super(Discriminator, self).__init__()
        self.main = nn.Sequential(
            nn.Conv2d(IMAGE_CHANNEL, D_HIDDEN, 4, 2, 1, bias=False),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(D_HIDDEN, D_HIDDEN * 2, 4, 2, 1, bias=False),
            nn.BatchNorm2d(D_HIDDEN * 2),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(D_HIDDEN * 2, D_HIDDEN * 4, 4, 2, 1, bias=False),
            nn.BatchNorm2d(D_HIDDEN * 4),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(D_HIDDEN * 4, D_HIDDEN * 8, 4, 2, 1, bias=False),
            nn.BatchNorm2d(D_HIDDEN * 8),
            nn.LeakyReLU(0.2, inplace=True),
            nn.Conv2d(D_HIDDEN * 8, 1, 4, 1, 0, bias=False),
            nn.Sigmoid()
        )

    def forward(self, input):
        return self.main(input).view(-1, 1).squeeze(1)
```

### Step 2: Implement Distributed Training

The `GANTrainer` class extends the custom itwinia `TorchTrainer` class and handles the initialization of models, optimizers, and the distributed training strategy for the GAN. The snippet below shows how the GANTrainer is extending the TorchTrainer class and initializing the parameters. This is essentially done to handle the scenario for the GAN which comproses of two Neaural Network models which is not handled by the TorchTrainer that looks expects and handles one model.

```python
class GANTrainer(TorchTrainer):
    def __init__(self,
                 config: Union[Dict, TrainingConfiguration],
                 epochs: int, discriminator: nn.Module,
                 generator: nn.Module,
                 strategy: Literal["ddp", "deepspeed", "horovod"] = 'ddp',
                 validation_every: Optional[int] = 1,
                 test_every: Optional[int] = None,
                 random_seed: Optional[int] = None,
                 logger: Optional[Logger] = None,
                 log_all_workers: bool = False,
                 metrics: Optional[Dict[str, Metric]] = None,
                 checkpoints_location: str = "checkpoints",
                 checkpoint_every: Optional[int] = None,
                 name: Optional[str] = None, **kwargs) -> None:
        super().__init__(config=config,
                         epochs=epochs,
                         model=None,
                         strategy=strategy,
                         validation_every=validation_every,
                         test_every=test_every,
                         random_seed=random_seed,
                         logger=logger,
                         log_all_workers=log_all_workers,
                         metrics=metrics,
                         checkpoints_location=checkpoints_location,
                         checkpoint_every=checkpoint_every,
                         name=name,
                         **kwargs)
        self.save_parameters(**self.locals2params(locals()))
        self.discriminator = discriminator
        self.generator = generator
        self.create_model_loss_optimizer()
```

We also create custom optimizers for the Optimizer and Discriminator GAN models:

```python

def create_model_loss_optimizer(self) -> None:
        self.optimizerD = optim.Adam(
            self.discriminator.parameters(), lr=self.config.lr, betas=(0.5, 0.999))
        self.optimizerG = optim.Adam(
            self.generator.parameters(), lr=self.config.lr, betas=(0.5, 0.999))
        self.criterion = nn.BCELoss()
        if self.strategy:
            self.discriminator, self.optimizerD, scheduler = self.strategy.distributed(self.discriminator, self.optimizerD)
            self.generator, self.optimizerG, scheduler = self.strategy.distributed(self.generator, self.optimizerG)


```

### Step 3: Training and Validation Logic

The training alternates between updating the Discriminator using real and generated images and training the Generator to fool the Discriminator.

```python
def train_step(self, real_images):
    # Training logic

   
```

Validation evaluates the performance of the Generator in deceiving the Discriminator.

```python
def validation_step(self, real_images):
    # Validation logic
```

### Step 4: Visualization and Monitoring

Training progress is monitored through visualizations of loss metrics and image samples generated periodically.

```python
def save_plots_and_images(self, epoch, real_images, fake_images):
    #  This method plots training losses and saving image samples
```

## Takeaways

This README describes steps taken to adapt a GAN for distributed training, aimed at enhancing efficiency and scalability for training on large-scale datasets. From this usecase we learn the following:

- atwinai `TorchTrainer` can easily be adapted to different unique usecases like the GAN that has two models.
- Training models in a distributed environment may require some level of customization in the training architecturing but it comes with lots of performance improvements.
- Distributed training for GANs requires a large dataset to reduce the chances of overfitting to the smaller data splits created during the training phase.
- Always ensure that both the models, data and results for a specific process are accessible on the same device during training and validation in a distributed environment.
