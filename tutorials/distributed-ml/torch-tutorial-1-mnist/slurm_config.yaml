account: intertwin
partition: develbooster
time: 00:20:00

distributed_strategy: ddp
std_out: slurm_job_logs/${distributed_strategy}.out
err_out: slurm_job_logs/${distributed_strategy}.err
job_name: ${distributed_strategy}-job

python_venv: ../../../.venv/

num_nodes: 1
gpus_per_node: 4
cpus_per_task: 16

training_cmd: "train.py -s {distributed_strategy} -c config.yaml"
