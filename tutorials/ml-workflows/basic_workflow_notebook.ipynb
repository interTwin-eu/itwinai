{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5064a94",
   "metadata": {},
   "source": [
    "# Basic Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e0f6a",
   "metadata": {},
   "source": [
    "The most simple workflow that you can write is a sequential pipeline of steps,\n",
    "where the outputs of a component are fed as input to the following component,\n",
    "employing a scikit-learn-like Pipeline.\n",
    "\n",
    "Itwinai defines each step as a \"component\". Components are implemented by extending\n",
    "the ``itwinai.components.BaseComponent`` class. Each component implements\n",
    "the `execute(...)` method, which provides a unified interface for interaction.\n",
    "\n",
    "The aim of itwinai components is to provide reusable machine learning best\n",
    "practices.\n",
    "To this end, some common operations are already encoded in abstract\n",
    "components. Some examples are:\n",
    "- ``DataGetter``: has no input and returns a dataset, collected from somewhere\n",
    "(e.g., downloaded).\n",
    "- ``DataSplitter``: splits an input dataset into train, validation and test.\n",
    "- ``DataPreproc``: perform preprocessing on train, validation, and test\n",
    "datasets.\n",
    "- ``Trainer``: trains an ML model and returns the trained model.\n",
    "- ``Saver``: saved an ML artifact (e.g., dataset, model) to disk.\n",
    "\n",
    "In this tutorial, you will see how to create new components and how they\n",
    "are assembled into sequential pipelines. Newly created components are\n",
    "in a separate file called 'basic_components.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c30284ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itwinai.pipeline import Pipeline\n",
    "\n",
    "# Import the custom components from file\n",
    "from basic_components import MyDataGetter, MyDatasetSplitter, MyTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "826fe8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<mlworkflows.basic_components.MyDataGetter object at 0x7fe1c81a5750>\n",
      "MyTrainer\n",
      "0.5\n",
      "#######################################\n",
      "# Starting execution of 'Pipeline'... #\n",
      "#######################################\n",
      "###########################################\n",
      "# Starting execution of 'MyDataGetter'... #\n",
      "###########################################\n",
      "#####################################\n",
      "# 'MyDataGetter' executed in 0.000s #\n",
      "#####################################\n",
      "################################################\n",
      "# Starting execution of 'MyDatasetSplitter'... #\n",
      "################################################\n",
      "##########################################\n",
      "# 'MyDatasetSplitter' executed in 0.000s #\n",
      "##########################################\n",
      "########################################\n",
      "# Starting execution of 'MyTrainer'... #\n",
      "########################################\n",
      "##################################\n",
      "# 'MyTrainer' executed in 0.000s #\n",
      "##################################\n",
      "#################################\n",
      "# 'Pipeline' executed in 0.001s #\n",
      "#################################\n",
      "Trained model:  my_trained_model\n",
      "<mlworkflows.basic_components.MyDataGetter object at 0x7fe1c86095a0>\n",
      "MyTrainer\n",
      "0.5\n",
      "#######################################\n",
      "# Starting execution of 'Pipeline'... #\n",
      "#######################################\n",
      "###########################################\n",
      "# Starting execution of 'MyDataGetter'... #\n",
      "###########################################\n",
      "#####################################\n",
      "# 'MyDataGetter' executed in 0.000s #\n",
      "#####################################\n",
      "################################################\n",
      "# Starting execution of 'MyDatasetSplitter'... #\n",
      "################################################\n",
      "##########################################\n",
      "# 'MyDatasetSplitter' executed in 0.000s #\n",
      "##########################################\n",
      "########################################\n",
      "# Starting execution of 'MyTrainer'... #\n",
      "########################################\n",
      "##################################\n",
      "# 'MyTrainer' executed in 0.000s #\n",
      "##################################\n",
      "#################################\n",
      "# 'Pipeline' executed in 0.000s #\n",
      "#################################\n",
      "Trained model:  my_trained_model\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Assemble them in a scikit-learn like pipeline\n",
    "    pipeline = Pipeline([\n",
    "        MyDataGetter(data_size=100),\n",
    "        MyDatasetSplitter(\n",
    "            train_proportion=.5,\n",
    "            validation_proportion=.25,\n",
    "            test_proportion=0.25\n",
    "        ),\n",
    "        MyTrainer()\n",
    "    ])\n",
    "\n",
    "    # Inspect steps\n",
    "    print(pipeline[0])\n",
    "    print(pipeline[2].name)\n",
    "    print(pipeline[1].train_proportion)\n",
    "\n",
    "    # Run pipeline\n",
    "    _, _, _, trained_model = pipeline.execute()\n",
    "    print(\"Trained model: \", trained_model)\n",
    "\n",
    "    # You can also create a Pipeline from a dict of components, which\n",
    "    # simplifies their retrieval by name\n",
    "    pipeline = Pipeline({\n",
    "        \"datagetter\": MyDataGetter(data_size=100),\n",
    "        \"splitter\": MyDatasetSplitter(\n",
    "            train_proportion=.5,\n",
    "            validation_proportion=.25,\n",
    "            test_proportion=0.25\n",
    "        ),\n",
    "        \"trainer\": MyTrainer()\n",
    "    })\n",
    "\n",
    "    # Inspect steps\n",
    "    print(pipeline[\"datagetter\"])\n",
    "    print(pipeline[\"trainer\"].name)\n",
    "    print(pipeline[\"splitter\"].train_proportion)\n",
    "\n",
    "    # Run pipeline\n",
    "    _, _, _, trained_model = pipeline.execute()\n",
    "    print(\"Trained model: \", trained_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
