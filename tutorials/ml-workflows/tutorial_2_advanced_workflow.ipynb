{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5064a94",
   "metadata": {},
   "source": [
    "# Advanced Workflow Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e0f6a",
   "metadata": {},
   "source": [
    "In the first two tutorials we saw how to define simple sequential workflows by\n",
    "means of the Pipeline object, which feds the outputs of the previous component\n",
    "as inputs of the following one.\n",
    "In this tutorial we show how to create more complex workflows, with\n",
    "non-sequential data flows. Here, components can be arranges as an directed\n",
    "acyclic graph (DAG). Under the DAG assumption, outputs of each block can be fed\n",
    "as input potentially to any other component, granting great flexibility to the\n",
    "experimenter.\n",
    "The trade-off for improved flexibility is a change in the way we define\n",
    "configuration files. From now on, it will only be possible to configure the\n",
    "parameters used by the training script, but not its structure through the\n",
    "Pipeline.\n",
    "\n",
    "itwinai provides a wrapper of jsonarparse's ArgumentParser which supports\n",
    "configuration files by default.\n",
    "\n",
    "To run as usual:\n",
    "> python my_script.py -d 20 --train-prop 0.7 --val-prop 0.2 --lr 1e-5\n",
    "\n",
    "To reuse the parameters saved in a configuration file and override some\n",
    "parameter (e.g., learning rate):\n",
    "> python my_script.py --config advanced_tutorial_conf.yaml --lr 2e-3\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c30284ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Any\n",
    "from itwinai.parser import ArgumentParser\n",
    "from itwinai.components import Predictor, monitor_exec\n",
    "\n",
    "from basic_components import (\n",
    "    MyDataGetter, MyDatasetSplitter, MyTrainer, MySaver\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "826fe8c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyEnsemblePredictor(Predictor):\n",
    "    @monitor_exec\n",
    "    def execute(self, dataset, model_ensemble) -> Any:\n",
    "        \"\"\"\n",
    "        do some predictions with model on dataset...\n",
    "        \"\"\"\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "66209fe0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] [-c CONFIG] [--print_config[=flags]]\n",
      "                             [--data-size DATA_SIZE] [--train-prop TRAIN_PROP]\n",
      "                             [--val-prop VAL_PROP] [--lr LR]\n",
      "error: Unrecognized arguments: --f=/root/.local/share/jupyter/runtime/kernel-v2-1380sKSE3x1G4bMG.json\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\u001b[0;31m:\u001b[0m 2\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    parser = ArgumentParser(description=\"itwinai advanced workflows tutorial\")\n",
    "    parser.add_argument(\n",
    "        \"--data-size\", \"-d\", type=int, required=True,\n",
    "        help=\"Dataset cardinality.\")\n",
    "    parser.add_argument(\n",
    "        \"--train-prop\", type=float, required=True,\n",
    "        help=\"Train split proportion.\")\n",
    "    parser.add_argument(\n",
    "        \"--val-prop\", type=float, required=True,\n",
    "        help=\"Validation split proportion.\")\n",
    "    parser.add_argument(\n",
    "        \"--lr\", type=float, help=\"Training learning rate.\")\n",
    "    args = parser.parse_args()\n",
    "\n",
    "    # Save parsed arguments to configuration file.\n",
    "    # Previous configurations are overwritten, which is not good,\n",
    "    # but the versioning of configuration files is out of the scope\n",
    "    # of this tutorial.\n",
    "    parser.save(\n",
    "        args, \"advanced_tutorial_conf.yaml\", format='yaml', overwrite=True)\n",
    "\n",
    "    # Define workflow components\n",
    "    getter = MyDataGetter(data_size=args.data_size)\n",
    "    splitter = MyDatasetSplitter(\n",
    "        train_proportion=args.train_prop,\n",
    "        validation_proportion=args.val_prop,\n",
    "        test_proportion=1-args.train_prop-args.val_prop\n",
    "    )\n",
    "    trainer1 = MyTrainer(lr=args.lr)\n",
    "    trainer2 = MyTrainer(lr=args.lr)\n",
    "    saver = MySaver()\n",
    "    predictor = MyEnsemblePredictor(model=None)\n",
    "\n",
    "    # Define ML workflow\n",
    "    dataset = getter.execute()\n",
    "    train_spl, val_spl, test_spl = splitter.execute(dataset)\n",
    "    _, _, _, trained_model1 = trainer1.execute(train_spl, val_spl, test_spl)\n",
    "    _, _, _, trained_model2 = trainer2.execute(train_spl, val_spl, test_spl)\n",
    "    _ = saver.execute(trained_model1)\n",
    "    predictions = predictor.execute(test_spl, [trained_model1, trained_model2])\n",
    "    print()\n",
    "    print(\"Predictions: \" + str(predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
