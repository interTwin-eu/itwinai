{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5064a94",
   "metadata": {},
   "source": [
    "# Pipeline and configuration files\n",
    "\n",
    "**Author(s)**: Matteo Bunino (CERN)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e0f6a",
   "metadata": {},
   "source": [
    "# Using Configuration Files in itwinai\n",
    "\n",
    "In the previous tutorial, we introduced how to create new components and assemble them into a \n",
    "**Pipeline** for a simplified workflow execution. The **Pipeline** executes components in the \n",
    "order they are defined, assuming that each component's outputs will fit as inputs to the next one.\n",
    "\n",
    "Sometimes, you might want to define your pipeline in a configuration **YAML** file instead. \n",
    "This allows for:\n",
    "\n",
    "- Easier modification and reuse of pipeline definitions\n",
    "- Clear separation between code and configuration\n",
    "- Dynamic overrides of parameters at runtime\n",
    "\n",
    "---\n",
    "\n",
    "## Example Configuration File\n",
    "\n",
    "```yaml\n",
    "training_pipeline:\n",
    "    _target_: itwinai.pipeline.Pipeline\n",
    "    steps:\n",
    "        - _target_: basic_components.MyDataGetter\n",
    "          data_size: 200\n",
    "        - _target_: basic_components.MyDatasetSplitter\n",
    "          train_proportion: 0.5\n",
    "          validation_proportion: 0.25\n",
    "          test_proportion: 0.25\n",
    "        - _target_: basic_components.MyTrainer\n",
    "        - _target_: basic_components.MySaver\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "itwinai leverages [Hydra](https://hydra.cc) to parse configuration files and instantiate pipelines dynamically. \n",
    "There is two ways you can use your configuration file to run a pipeline: from the command-line \n",
    "interface (CLI) or from within your code.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97fe421a",
   "metadata": {},
   "source": [
    "## Parsing Pipelines from CLI\n",
    "\n",
    "You can execute a pipeline from a configuration file with the CLI using:\n",
    "\n",
    "```bash\n",
    "itwinai exec-pipeline\n",
    "```\n",
    "\n",
    "This command loads the default configuration file and executes the defined \n",
    "pipeline. You can customize execution using the following options:\n",
    "\n",
    "### 1. Setting a `--config-path` and `--config-name`\n",
    "By default, the parser will look for a file called config.yaml inside your current working directory. \n",
    "If you want to change this, set the path to your configuration file with the `--config-path` option. \n",
    "This can be either absolute or relative to your current working directory, and should point to\n",
    "the directory in which your configuration file is located. If your configuration file has a different name \n",
    "(not config.yaml), you may specify this with the `--config-name` flag:\n",
    "\n",
    "```bash\n",
    "itwinai exec-pipeline --config-path path/to/dir --config-name my-config-file\n",
    "```\n",
    "\n",
    "### 2. Setting a Pipeline Key (`pipe_key`)\n",
    "A configuration file can contain multiple pipelines. \n",
    "The default key that the parser will look for is `training_pipeline`. Use the `pipe_key` argument \n",
    "to overwrite this default and specify which pipeline to execute:\n",
    "\n",
    "```bash\n",
    "itwinai exec-pipeline +pipe_key=another_training_pipeline\n",
    "```\n",
    "\n",
    "### 3. Selecting Steps to Run (`pipe_steps`)\n",
    "\n",
    "If you only want to run specific steps of the pipeline, use `pipe_steps`:\n",
    "\n",
    "```bash\n",
    "itwinai exec-pipeline +pipe_steps=[data_loader,trainer]\n",
    "```\n",
    "\n",
    "This will execute only the `data_loading` and `training` steps of the pipeline. You can also give \n",
    "`pipe_steps` as a list of indices, if your configuration file defines your steps in list format.\n",
    "\n",
    "### 4. Overwriting Values\n",
    "\n",
    "You can override any parameter in the configuration file directly from the command line:\n",
    "\n",
    "```bash\n",
    "itwinai exec-pipeline +trainer.batch_size=64\n",
    "```\n",
    "\n",
    "This modifies the `batch_size` parameter inside the pipeline configuration.\n",
    "\n",
    "---\n",
    "\n",
    "## Advanced Functionality with Hydra\n",
    "\n",
    "Since this implementation is based on **Hydra**, you can use all of Hydraâ€™s command-line arguments, including:\n",
    "\n",
    "- **Multi-run execution:**\n",
    "- **Configuration composition and overrides**\n",
    "- **Experiment tracking with different configurations**\n",
    "\n",
    "For more details, refer to the [Hydra documentation](https://hydra.cc/docs/advanced/hydra-command-line-flags/).\n",
    "\n",
    "---\n",
    "\n",
    "## Debugging Tip\n",
    "\n",
    "If your pipeline execution fails and you need detailed error messages, set the following environment variable before running the pipeline:\n",
    "\n",
    "```bash\n",
    "export HYDRA_FULL_ERROR=1\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "TODO: \n",
    "serialization (the other way around)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "783d15c8",
   "metadata": {},
   "source": [
    "## Parsing Pipelines from Code\n",
    "\n",
    "In some cases, you may want to parse and execute a pipeline from a configuration file from within your python code. \n",
    "You can do this by running: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2cebaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from hydra import compose, initialize\n",
    "from itwinai import exec_pipeline_with_compose\n",
    "\n",
    "# Here, we show how to run a pre-existing pipeline stored as\n",
    "# a configuration file from within python code, with the possibility of dynamically\n",
    "# override some fields\n",
    "\n",
    "# Load pipeline from saved YAML (dynamic deserialization)\n",
    "with initialize(config_path=\"path/to/my/config\"):\n",
    "    cfg = compose(\n",
    "        config_name=\"basic_pipeline_example.yaml\",\n",
    "        overrides=[\n",
    "            \"pipeline.init_args.steps.0.init_args.data_size=200\",\n",
    "        ],\n",
    "    )\n",
    "    exec_pipeline_with_compose(cfg)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89aef09",
   "metadata": {},
   "source": [
    "To keep things simple, this implementation is taken directly from Hydra, so please refer to \n",
    "[their documentation](https://hydra.cc/docs/advanced/compose_api/) for more details on what parameters you can set here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cff1841c",
   "metadata": {},
   "source": [
    "## Reproducibility\n",
    "\n",
    "Each execution logs the pipeline configuration under the `outputs/` directory. \n",
    "This ensures reproducibility by recording the exact parameters used for execution. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad31f43c",
   "metadata": {},
   "source": [
    "## Running the pipeline\n",
    "\n",
    "Here you can find a graphical representation of the pipeline implemented below.\n",
    "\n",
    "![pipeline](sample_pipeline_2.jpg)\n",
    "\n",
    "### Important!\n",
    "\n",
    "Pipeline components can be serialized only when they are imported from an external file!\n",
    "\n",
    "In this case, `MyDataGetter`, `MyDatasetSplitter`, and `MyTrainer` are imported from `basic_components`.\n",
    "Otherwise, the pipe serialization cannot be deserialized by another process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a7391f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MyDataGetter's data_size is now: 200\n",
      "\n",
      "#######################################\n",
      "# Starting execution of 'Pipeline'... #\n",
      "#######################################\n",
      "###########################################\n",
      "# Starting execution of 'MyDataGetter'... #\n",
      "###########################################\n",
      "#####################################\n",
      "# 'MyDataGetter' executed in 0.000s #\n",
      "#####################################\n",
      "################################################\n",
      "# Starting execution of 'MyDatasetSplitter'... #\n",
      "################################################\n",
      "##########################################\n",
      "# 'MyDatasetSplitter' executed in 0.000s #\n",
      "##########################################\n",
      "########################################\n",
      "# Starting execution of 'MyTrainer'... #\n",
      "########################################\n",
      "##################################\n",
      "# 'MyTrainer' executed in 0.000s #\n",
      "##################################\n",
      "######################################\n",
      "# Starting execution of 'Adapter'... #\n",
      "######################################\n",
      "################################\n",
      "# 'Adapter' executed in 0.000s #\n",
      "################################\n",
      "######################################\n",
      "# Starting execution of 'MySaver'... #\n",
      "######################################\n",
      "################################\n",
      "# 'MySaver' executed in 0.000s #\n",
      "################################\n",
      "#################################\n",
      "# 'Pipeline' executed in 0.001s #\n",
      "#################################\n",
      "Trained model (2):  my_trained_model\n"
     ]
    }
   ],
   "source": [
    "from hydra import compose, initialize\n",
    "from itwinai import exec_pipeline_with_compose\n",
    "\n",
    "# Here, we show how to run a pre-existing pipeline stored as\n",
    "# a configuration file from within python code, with the possibility of dynamically\n",
    "# override some fields\n",
    "\n",
    "# Load pipeline from saved YAML (dynamic deserialization)\n",
    "with initialize():\n",
    "    cfg = compose(\n",
    "        \"basic_pipeline_example.yaml\",\n",
    "        overrides=[\n",
    "            \"pipeline.init_args.steps.0.init_args.data_size=200\",\n",
    "        ],\n",
    "    )\n",
    "    exec_pipeline_with_compose(cfg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
