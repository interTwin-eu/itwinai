hpo_training_pipeline:
  _target_: itwinai.pipeline.Pipeline
  steps:
    - _target_: data.FashionMNISTGetter
    - _target_: data.FashionMNISTSplitter
      train_proportion: 0.9
      validation_proportion: 0.1
      test_proportion: 0.0
    - _target_: trainer.MyRayTorchTrainer
      config:
        scaling_config:
            num_workers: 2
            use_gpu: true
            resources_per_worker:
              CPU: 6
              GPU: 1
        train_loop_config:
          batch_size:
            type: choice
            categories: [32, 64, 128]
          learning_rate:
            type: uniform
            lower: 1e-5
            upper: 1e-3
          epochs: 10
        tune_config:
          num_samples: 4
          scheduler:
            name: asha
            max_t: 10
            grace_period: 5
            reduction_factor: 4
            brackets: 1
          # search_alg:
          #   name: bayes
          #   metric: loss
          #   mode: min
          #   n_random_steps: 5
        run_config:
          storage_path: ray_checkpoints
          name: Virgo-HPO-Experiment
      strategy: deepspeed
      logger:
        _target_: itwinai.loggers.LoggersCollection
        loggers:
          - _target_: itwinai.loggers.MLFlowLogger
            experiment_name: MNIST HPO Experiment
            log_freq: batch