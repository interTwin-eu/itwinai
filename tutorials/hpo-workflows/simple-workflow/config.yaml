batch_size: 64
learning_rate: 0.0001

training_pipeline:
  class_path: itwinai.pipeline.Pipeline
  init_args:
    steps:
      - class_path: data.FashionMNISTGetter
      - class_path: data.FashionMNISTSplitter
        init_args: 
          train_proportion: 0.9
          validation_proportion: 0.1
      - class_path: trainer.MyTrainer
        init_args:
          config:
            optim_lr: ${learning_rate}    # This will be overridden by the Ray Tuner
            batch_size: ${batch_size}  # This will be overridden by the Ray Tuner
          strategy: ddp
          epochs: 5
          logger:
            class_path: itwinai.loggers.LoggersCollection
            init_args:
              loggers:
                - class_path: itwinai.loggers.MLFlowLogger
                  init_args:
                    experiment_name: Simple HPO MNIST Experiment
                    log_freq: batch