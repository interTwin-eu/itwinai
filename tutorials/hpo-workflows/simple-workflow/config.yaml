batch_size: 64
learning_rate: 0.0001

training_pipeline:
  _target_: itwinai.pipeline.Pipeline
  steps:
    - _target_: data.FashionMNISTGetter
    - _target_: data.FashionMNISTSplitter
      train_proportion: 0.9
      validation_proportion: 0.1
    - _target_: trainer.MyTrainer
      config:
        optim_lr: ${learning_rate}    # This will be overridden by the Ray Tuner
        batch_size: ${batch_size}  # This will be overridden by the Ray Tuner
      strategy: ddp
      epochs: 5
      logger:
        _target_: itwinai.loggers.LoggersCollection
        loggers:
          - _target_: itwinai.loggers.MLFlowLogger
            experiment_name: Simple HPO MNIST Experiment
            log_freq: batch