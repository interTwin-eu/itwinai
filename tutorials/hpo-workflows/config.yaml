hpo_training_pipeline:
  class_path: itwinai.pipeline.Pipeline
  init_args:
    steps:
      - class_path: data.FashionMNISTGetter
      - class_path: data.FashionMNISTSplitter
        init_args: 
          train_proportion: 0.9
          validation_proportion: 0.1
          test_proportion: 0.0
      - class_path: trainer.MyRayTorchTrainer
        init_args:
          config:
            scaling_config:
                num_workers: 2
                use_gpu: true
                resources_per_worker:
                  CPU: 6
                  GPU: 1
            train_loop_config:
              batch_size:
                type: choice
                options: [32, 64, 128]
              learning_rate:
                type: uniform
                min: 1e-5
                max: 1e-3
              epochs: 10
            tune_config:
              num_samples: 4
              scheduler:
                name: asha
                max_t: 10
                grace_period: 5
                reduction_factor: 4
                brackets: 1
              # search_alg:
              #   name: bayes
              #   metric: loss
              #   mode: min
              #   n_random_steps: 5
            run_config:
              storage_path: ray_checkpoints
              name: Virgo-HPO-Experiment
          strategy: deepspeed
          logger:
            class_path: itwinai.loggers.LoggersCollection
            init_args:
              loggers:
                - class_path: itwinai.loggers.MLFlowLogger
                  init_args:
                    experiment_name: MNIST HPO Experiment
                    log_freq: batch