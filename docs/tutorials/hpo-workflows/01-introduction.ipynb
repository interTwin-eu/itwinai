{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter Optimization with RayTorchTrainer on MNIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This tutorial provides a step-by-step guide to using the ```RayTorchTrainer``` class for conducting a hyperparameter optimization (HPO) study. To illustrate this we will be using the MNIST dataset. You will see that the code we are writing is not that different from if we were using simply the itwinai TorchTrainer, but we have to make some little tweaks to make it compatible with the ray backend. By the end of this tutorial, you will\n",
    "- understand how the RayTorchTrainer functions\n",
    "- know how to create a configuration file to define your HPO study\n",
    "- implement the coding steps required to define and run an HPO study with the itwinai training pipeline\n",
    "\n",
    "You can find the full code for this tutorial on github .... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setting up the Model\n",
    "\n",
    "To start off, let's first install some libraries that we will need to create our pytorch model, import the MNIST dataset, and run our HPO study. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Literal\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.optim import Adam\n",
    "from torchvision.models import resnet18\n",
    "\n",
    "from itwinai.loggers import Logger\n",
    "from itwinai.torch.config import TrainingConfiguration\n",
    "from itwinai.torch.distributed import RayDeepSpeedStrategy\n",
    "from itwinai.torch.trainer import RayTorchTrainer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's define our trainer class. You will see that the structure is very similar to that of the itwinai TorchTrainer, but we will move a few things into the train() function that are normally done outside of it. This is because ray distributes the trials only when the train() function is called. We will tune two hyperparameters, the batch size and the learning rate, for a resnet18 model that we will train on the FashionMNIST dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyRayTorchTrainer(RayTorchTrainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Dict,\n",
    "        strategy: Literal[\"ddp\", \"deepspeed\"] = \"ddp\",\n",
    "        name: str | None = None,\n",
    "        logger: Logger | None = None,\n",
    "    ) -> None:\n",
    "        super().__init__(config=config, strategy=strategy, name=name, logger=logger)\n",
    "\n",
    "    def create_model_loss_optimizer(self):\n",
    "        model = resnet18(num_classes=10)\n",
    "        model.conv1 = torch.nn.Conv2d(\n",
    "            1, 64, kernel_size=(7, 7), stride=(1, 1), padding=(3, 3), bias=False\n",
    "        )\n",
    "        # First, define strategy-wise optional configurations\n",
    "        if isinstance(self.strategy, RayDeepSpeedStrategy):\n",
    "            distribute_kwargs = dict(\n",
    "                config_params=dict(\n",
    "                    train_micro_batch_size_per_gpu=self.training_config[\"batch_size\"]\n",
    "                )\n",
    "            )\n",
    "        else:\n",
    "            distribute_kwargs = {}\n",
    "        optimizer = Adam(model.parameters(), lr=self.training_config[\"learning_rate\"])\n",
    "        self.model, self.optimizer, _ = self.strategy.distributed(\n",
    "            model, optimizer, **distribute_kwargs\n",
    "        )\n",
    "        self.loss = CrossEntropyLoss()\n",
    "\n",
    "    def train(self, config, data):\n",
    "        self.training_config = config\n",
    "\n",
    "        # Because of the way the ray cluster is set up,\n",
    "        # the initialisation of the strategy and logger, as well as the creation of the\n",
    "        # model, loss, optimizer and dataloader are done from within the train() function\n",
    "        self.strategy.init()\n",
    "        self.initialize_logger(\n",
    "            hyperparams=self.training_config, rank=self.strategy.global_rank()\n",
    "        )\n",
    "        self.create_model_loss_optimizer()\n",
    "        self.create_dataloaders(\n",
    "            train_dataset=data[0], validation_dataset=data[1], test_dataset=data[2]\n",
    "        )\n",
    "\n",
    "        for epoch in range(self.training_config[\"epochs\"]):\n",
    "            if self.strategy.global_world_size() > 1:\n",
    "                self.set_epoch(epoch)\n",
    "\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "\n",
    "            for images, labels in self.train_dataloader:\n",
    "                if isinstance(self.strategy, RayDeepSpeedStrategy):\n",
    "                    device = self.strategy.device()\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self.model(images)\n",
    "                train_loss = self.loss(outputs, labels)\n",
    "                self.optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_losses.append(train_loss.detach().cpu().numpy())\n",
    "\n",
    "            for images, labels in self.validation_dataloader:\n",
    "                if isinstance(self.strategy, RayDeepSpeedStrategy):\n",
    "                    device = self.strategy.device()\n",
    "                    images, labels = images.to(device), labels.to(device)\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(images)\n",
    "                    val_loss = self.loss(outputs, labels)\n",
    "                val_losses.append(val_loss.detach().cpu().numpy())\n",
    "\n",
    "            self.log(np.mean(train_losses), \"train_loss\", kind=\"metric\", step=epoch)\n",
    "            self.log(np.mean(val_losses), \"val_loss\", kind=\"metric\", step=epoch)\n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch,\n",
    "                \"loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "            }\n",
    "            metrics = {\"loss\": val_loss.item()}\n",
    "            self.checkpoint_and_report(\n",
    "                epoch, tuning_metrics=metrics, checkpointing_data=checkpoint\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "class MyTrainer(TorchTrainer):\n",
    "    def __init__(\n",
    "        self,\n",
    "        config: Dict | TrainingConfiguration | None = None,\n",
    "        strategy: Literal[\"ddp\", \"deepspeed\", \"horovod\"] = \"ddp\",\n",
    "        name: str | None = None,\n",
    "        logger: Logger | None = None,\n",
    "    ) -> None:\n",
    "        self.config = config\n",
    "        super().__init__(config=config, strategy=strategy, name=name, logger=logger)\n",
    "\n",
    "    def create_model_loss_optimizer(self):\n",
    "        model = resnet18(num_classes=10)\n",
    "        model.conv1 = torch.nn.Conv2d(\n",
    "            1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False\n",
    "        )\n",
    "        # First, define strategy-wise optional configurations\n",
    "        if isinstance(self.strategy, DeepSpeedStrategy):\n",
    "            distribute_kwargs = dict(\n",
    "                config_params=dict(train_micro_batch_size_per_gpu=self.config.batch_size)\n",
    "            )\n",
    "        else:\n",
    "            distribute_kwargs = {}\n",
    "        optimizer = Adam(model.parameters(), lr=self.config.learning_rate)\n",
    "        self.model, self.optimizer, _ = self.strategy.distributed(\n",
    "            model, optimizer, **distribute_kwargs\n",
    "        )\n",
    "        self.loss = CrossEntropyLoss()\n",
    "\n",
    "    def train(self, config, data):\n",
    "        # self.training_config = config\n",
    "\n",
    "        # self.strategy.init()\n",
    "        # self.initialize_logger(hyperparams=config, rank=self.strategy.global_rank())\n",
    "        # self.create_model_loss_optimizer()\n",
    "        # self.create_dataloaders(\n",
    "        #     train_dataset=data[0],\n",
    "        #     validation_dataset=data[1],\n",
    "        #     test_dataset=data[2]\n",
    "        # )\n",
    "\n",
    "        for epoch in range(self.training_config[\"epochs\"]):\n",
    "            if self.strategy.global_world_size() > 1:\n",
    "                self.set_epoch(epoch)\n",
    "\n",
    "            train_losses = []\n",
    "            val_losses = []\n",
    "\n",
    "            for images, labels in enumerate(self.train_dataloader):\n",
    "                # if isinstance(self.strategy, RayDeepspeedStrategy):\n",
    "                device = self.strategy.device()\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = self.model(images)\n",
    "                train_loss = self.loss(outputs, labels)\n",
    "                self.optimizer.zero_grad()\n",
    "                train_loss.backward()\n",
    "                self.optimizer.step()\n",
    "                train_losses.append(train_loss)\n",
    "\n",
    "            for images, labels in enumerate(self.validation_dataloader):\n",
    "                # if isinstance(self.strategy, RayDeepspeedStrategy):\n",
    "                device = self.strategy.device()\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                with torch.no_grad():\n",
    "                    outputs = self.model(images)\n",
    "                    val_loss = self.loss(outputs, labels)\n",
    "                val_losses.append(val_loss)\n",
    "\n",
    "            self.log(np.mean(train_losses), \"train_loss\", kind=\"metric\", step=epoch)\n",
    "            self.log(np.mean(val_losses), \"val_loss\", kind=\"metric\", step=epoch)\n",
    "            checkpoint = {\n",
    "                \"epoch\": epoch,\n",
    "                \"loss\": train_loss,\n",
    "                \"val_loss\": val_loss,\n",
    "            }\n",
    "            checkpoint_filename = self.checkpoints_location.format(epoch)\n",
    "            torch.save(checkpoint, checkpoint_filename)\n",
    "            self.log(\n",
    "                checkpoint_filename,\n",
    "                os.path.basename(checkpoint_filename),\n",
    "                kind=\"artifact\",\n",
    "            )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring our training\n",
    "Next, we will write a training configuration to define our HPO workflow. Once again, this configuration will look very similar to any other itwinai pipeline configuration, but we will add some HPO specific parameters to define our search space, search algorithm and scheduling algorithm. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "ray_training_pipeline:\n",
    "  class_path: itwinai.pipeline.Pipeline\n",
    "  init_args:\n",
    "    steps:\n",
    "      - class_path: data.FashionMNISTGetter\n",
    "      - class_path: data.FashionMNISTSplitter\n",
    "        init_args: \n",
    "          train_proportion: 0.9\n",
    "          validation_proportion: 0.1\n",
    "      - class_path: trainer.MyRayTorchTrainer\n",
    "        init_args:\n",
    "          config:\n",
    "            scaling_config:\n",
    "                num_workers: 4\n",
    "                use_gpu: true\n",
    "                resources_per_worker:\n",
    "                  CPU: 5\n",
    "                  GPU: 1\n",
    "            train_loop_config:\n",
    "              batch_size:\n",
    "                type: choice\n",
    "                options: [32, 64, 128]\n",
    "              learning_rate:\n",
    "                type: uniform\n",
    "                min: 1e-5\n",
    "                max: 1e-3\n",
    "              epochs: 20\n",
    "            tune_config:\n",
    "              num_samples: 2\n",
    "              scheduler:\n",
    "                name: asha\n",
    "                max_t: 20\n",
    "                grace_period: 10\n",
    "                reduction_factor: 4\n",
    "                brackets: 1\n",
    "              search_alg:\n",
    "                name: bayes\n",
    "                metric: loss\n",
    "                mode: min\n",
    "                n_random_steps: 5\n",
    "            run_config:\n",
    "              storage_path: ray_checkpoints\n",
    "              name: Virgo-HPO-Experiment\n",
    "          strategy: ddp\n",
    "          logger:\n",
    "            class_path: itwinai.loggers.LoggersCollection\n",
    "            init_args:\n",
    "              loggers:\n",
    "                - class_path: itwinai.loggers.MLFlowLogger\n",
    "                  init_args:\n",
    "                    experiment_name: MNIST HPO Experiment\n",
    "                    log_freq: batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```yaml\n",
    "training_pipeline:\n",
    "  class_path: itwinai.pipeline.Pipeline\n",
    "  init_args:\n",
    "    steps:\n",
    "      - class_path: data.FashionMNISTGetter\n",
    "      - class_path: data.FashionMNISTSplitter\n",
    "        init_args: \n",
    "          train_proportion: 0.9\n",
    "          validation_proportion: 0.1\n",
    "      - class_path: trainer.MyRayTrainer\n",
    "        init_args:\n",
    "          strategy: ddp\n",
    "          epochs: 20\n",
    "          checkpoints_location: checkpoints\n",
    "          logger:\n",
    "            class_path: itwinai.loggers.LoggersCollection\n",
    "            init_args:\n",
    "              loggers:\n",
    "                - class_path: itwinai.loggers.MLFlowLogger\n",
    "                  init_args:\n",
    "                    experiment_name: MNIST Experiment\n",
    "                    log_freq: batch\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, let's break down the arguments to our ```MyRayTorchTrainer``` class. \n",
    "1. The ```scaling_config``` argument defines how we distribute ressources between our trials. To learn more about the options for setting ressources, please refer to the [ray train documentation](https://docs.ray.io/en/latest/train/user-guides/using-gpus.html) on this topic.\n",
    "2. In the ```train_loop_config``` we define which hyperparameters we want to tune, as well as any additional parameters that we want to pass to our train() \n",
    " function. For the tunable parameters we have to specify the type and define their domain. For more information on which parameter types are possible and how to define their domains, have a look at [this page](https://docs.ray.io/en/latest/tune/api/search_space.html), and learn how to define their domains according to the ```RayTorchTrainer```'s specifications [here](https://github.com/interTwin-eu/itwinai/blob/ray-torchtrainer-integration/src/itwinai/torch/trainer.py#L1472).\n",
    "3. In the ```tune_config``` we configure which search algorithm and scheduler to use to search the hyperparameter space and sample new configurations. All search algorithms and schedulers supported by ray tune are also supported by us. You can refer to the ray documentation to learn more about the supported [search algorithms](https://docs.ray.io/en/latest/tune/api/suggestion.html#tune-search-alg) and [schedulers](https://docs.ray.io/en/latest/tune/api/schedulers.html).\n",
    "4.  The ```run_config``` defines a path that is used for checkpointing. This is mandatory to set if you want to distribute individual trials across more than one node, because ray uses this as a shared directory to coordinate and share data generated on each of the nodes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running our code\n",
    "Great! So we have created our custom trainer inheriting from the ```RayTorchTrainer```, and we have defined our pipeline in a configuration file. Now, all that is left to do is launch our training:\n",
    "````bash\n",
    "cd tutorials/hpo-workflows\n",
    "sbatch slurm_hpo.sh\n",
    "````"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "envAI_juwels",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
