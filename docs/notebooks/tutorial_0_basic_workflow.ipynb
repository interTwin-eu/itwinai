{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5064a94",
   "metadata": {},
   "source": [
    "# Basic Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e0f6a",
   "metadata": {},
   "source": [
    "The most simple workflow that you can write is a sequential pipeline of steps,\n",
    "where the outputs of a component are fed as input to the following component,\n",
    "employing a scikit-learn-like Pipeline.\n",
    "\n",
    "Itwinai defines each step as a \"component\". Components are implemented by extending\n",
    "the ``itwinai.components.BaseComponent`` class. Each component implements\n",
    "the `execute(...)` method, which provides a unified interface for interaction.\n",
    "\n",
    "The aim of itwinai components is to provide reusable machine learning best\n",
    "practices.\n",
    "To this end, some common operations are already encoded in abstract\n",
    "components. Some examples are:\n",
    "- ``DataGetter``: has no input and returns a dataset, collected from somewhere\n",
    "(e.g., downloaded).\n",
    "- ``DataSplitter``: splits an input dataset into train, validation and test.\n",
    "- ``DataPreproc``: perform preprocessing on train, validation, and test\n",
    "datasets.\n",
    "- ``Trainer``: trains an ML model and returns the trained model.\n",
    "- ``Saver``: saved an ML artifact (e.g., dataset, model) to disk.\n",
    "\n",
    "In this tutorial, you will see how to create new components and how they\n",
    "are assembled into sequential pipelines. Newly created components are\n",
    "in a separate file called 'basic_components.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "c30284ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itwinai.pipeline import Pipeline\n",
    "# Import the custom components from file\n",
    "from typing import List, Optional, Tuple, Any\n",
    "from itwinai.components import (\n",
    "    DataGetter, DataSplitter, Trainer, Saver, monitor_exec\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0947b06",
   "metadata": {},
   "source": [
    "## Component interface implementation\n",
    "Here we show how to implement component interfaces in a simple way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "5c368cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyDataGetter(DataGetter):\n",
    "    def __init__(self, data_size: int, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.data_size = data_size\n",
    "        self.save_parameters(data_size=data_size)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(self) -> List[int]:\n",
    "        \"\"\"Return a list dataset.\n",
    "\n",
    "        Returns:\n",
    "            List[int]: dataset\n",
    "        \"\"\"\n",
    "        return list(range(self.data_size))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "72ff5009",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDatasetSplitter(DataSplitter):\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        dataset: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int]]:\n",
    "        \"\"\"Splits a list dataset into train, validation and test datasets.\n",
    "\n",
    "        Args:\n",
    "            dataset (List[int]): input list dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int]]: train, validation, and\n",
    "            test datasets respectively.\n",
    "        \"\"\"\n",
    "        train_n = int(len(dataset)*self.train_proportion)\n",
    "        valid_n = int(len(dataset)*self.validation_proportion)\n",
    "        train_set = dataset[:train_n]\n",
    "        vaild_set = dataset[train_n:train_n+valid_n]\n",
    "        test_set = dataset[train_n+valid_n:]\n",
    "        return train_set, vaild_set, test_set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75bfdf4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, lr: float = 1e-3, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.save_parameters(name=name, lr=lr)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        train_set: List[int],\n",
    "        vaild_set: List[int],\n",
    "        test_set: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int], str]:\n",
    "        \"\"\"Dummy ML trainer mocking a ML training algorithm.\n",
    "\n",
    "        Args:\n",
    "            train_set (List[int]): training dataset.\n",
    "            vaild_set (List[int]): validation dataset.\n",
    "            test_set (List[int]): test dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int], str]: train, validation,\n",
    "            test datasets, and trained model.\n",
    "        \"\"\"\n",
    "        return train_set, vaild_set, test_set, \"my_trained_model\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "915bede2",
   "metadata": {},
   "source": [
    "## Component Assembly\n",
    "Finally, we assemble the components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "826fe8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<__main__.MyDataGetter object at 0x7fe1c81a4f10>\n",
      "MyTrainer\n",
      "0.5\n",
      "#######################################\n",
      "# Starting execution of 'Pipeline'... #\n",
      "#######################################\n",
      "###########################################\n",
      "# Starting execution of 'MyDataGetter'... #\n",
      "###########################################\n",
      "#####################################\n",
      "# 'MyDataGetter' executed in 0.000s #\n",
      "#####################################\n",
      "################################################\n",
      "# Starting execution of 'MyDatasetSplitter'... #\n",
      "################################################\n",
      "##########################################\n",
      "# 'MyDatasetSplitter' executed in 0.000s #\n",
      "##########################################\n",
      "########################################\n",
      "# Starting execution of 'MyTrainer'... #\n",
      "########################################\n",
      "##################################\n",
      "# 'MyTrainer' executed in 0.000s #\n",
      "##################################\n",
      "#################################\n",
      "# 'Pipeline' executed in 0.002s #\n",
      "#################################\n",
      "Trained model:  my_trained_model\n",
      "<__main__.MyDataGetter object at 0x7fe1c86095a0>\n",
      "MyTrainer\n",
      "0.5\n",
      "#######################################\n",
      "# Starting execution of 'Pipeline'... #\n",
      "#######################################\n",
      "###########################################\n",
      "# Starting execution of 'MyDataGetter'... #\n",
      "###########################################\n",
      "#####################################\n",
      "# 'MyDataGetter' executed in 0.000s #\n",
      "#####################################\n",
      "################################################\n",
      "# Starting execution of 'MyDatasetSplitter'... #\n",
      "################################################\n",
      "##########################################\n",
      "# 'MyDatasetSplitter' executed in 0.000s #\n",
      "##########################################\n",
      "########################################\n",
      "# Starting execution of 'MyTrainer'... #\n",
      "########################################\n",
      "##################################\n",
      "# 'MyTrainer' executed in 0.000s #\n",
      "##################################\n",
      "#################################\n",
      "# 'Pipeline' executed in 0.000s #\n",
      "#################################\n",
      "Trained model:  my_trained_model\n"
     ]
    }
   ],
   "source": [
    "# Assemble them in a scikit-learn like pipeline\n",
    "pipeline = Pipeline([\n",
    "    MyDataGetter(data_size=100),\n",
    "    MyDatasetSplitter(\n",
    "        train_proportion=.5,\n",
    "        validation_proportion=.25,\n",
    "        test_proportion=0.25\n",
    "    ),\n",
    "    MyTrainer()\n",
    "])\n",
    "\n",
    "# Inspect steps\n",
    "print(pipeline[0])\n",
    "print(pipeline[2].name)\n",
    "print(pipeline[1].train_proportion)\n",
    "\n",
    "# Run pipeline\n",
    "_, _, _, trained_model = pipeline.execute()\n",
    "print(\"Trained model: \", trained_model)\n",
    "\n",
    "# You can also create a Pipeline from a dict of components, which\n",
    "# simplifies their retrieval by name\n",
    "pipeline = Pipeline({\n",
    "    \"datagetter\": MyDataGetter(data_size=100),\n",
    "    \"splitter\": MyDatasetSplitter(\n",
    "        train_proportion=.5,\n",
    "        validation_proportion=.25,\n",
    "        test_proportion=0.25\n",
    "    ),\n",
    "    \"trainer\": MyTrainer()\n",
    "})\n",
    "\n",
    "# Inspect steps\n",
    "print(pipeline[\"datagetter\"])\n",
    "print(pipeline[\"trainer\"].name)\n",
    "print(pipeline[\"splitter\"].train_proportion)\n",
    "\n",
    "# Run pipeline\n",
    "_, _, _, trained_model = pipeline.execute()\n",
    "print(\"Trained model: \", trained_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
