{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5064a94",
   "metadata": {},
   "source": [
    "# Basic Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588e0f6a",
   "metadata": {},
   "source": [
    "The most simple workflow that you can write is a sequential pipeline of steps,\n",
    "where the outputs of a component are fed as input to the following component,\n",
    "employing a scikit-learn-like Pipeline.\n",
    "\n",
    "In itwinai, a step is also called \"component\" and is implemented by extending\n",
    "the ``itwinai.components.BaseComponent`` class. Each component implements\n",
    "the `execute(...)` method, which provides a unified interface to interact with\n",
    "each component.\n",
    "\n",
    "The aim of itwinai components is to provide reusable machine learning best\n",
    "practices, and some common operations are already encoded in some abstract\n",
    "components. Some examples are:\n",
    "- ``DataGetter``: has no input and returns a dataset, collected from somewhere\n",
    "(e.g., downloaded).\n",
    "- ``DataSplitter``: splits an input dataset into train, validation and test.\n",
    "- ``DataPreproc``: perform preprocessing on train, validation, and test\n",
    "datasets.\n",
    "- ``Trainer``: trains an ML model and returns the trained model.\n",
    "- ``Saver``: saved an ML artifact (e.g., dataset, model) to disk.\n",
    "\n",
    "In this tutorial you will see how to create new components and how they\n",
    "are assembled into sequential pipelines. Newly created components are\n",
    "in a separate file called 'basic_components.py'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "579ddcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/root/itwinai/itwinai\n",
      "AUTHORS.md       COPYRIGHT  \u001b[0m\u001b[01;34mUNKNOWN.egg-info\u001b[0m/  pyproject.toml  \u001b[01;34muse-cases\u001b[0m/\n",
      "CHANGELOG        LICENSE    \u001b[01;34mbuild\u001b[0m/             \u001b[01;34msrc\u001b[0m/\n",
      "CODEOWNERS       Makefile   \u001b[01;34mdocs\u001b[0m/              \u001b[01;34mtests\u001b[0m/\n",
      "CONTRIBUTING.md  README.md  \u001b[01;34menv-files\u001b[0m/         \u001b[01;34mtutorials\u001b[0m/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/itwinai/itwinai/.venv-docs/lib/python3.10/site-packages/IPython/core/magics/osm.py:417: UserWarning: This is now an optional IPython functionality, setting dhist requires you to install the `pickleshare` library.\n",
      "  self.shell.db['dhist'] = compress_dhist(dhist)[-100:]\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "# sys.path.enter('../')\n",
    "# import os\n",
    "# os.getcwd()\n",
    "# %cd ..\n",
    "%ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "34eaf496",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib  \n",
    "foobar = importlib.import_module(\"tutorials.ml-workflows\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7cb71fce",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (4188913185.py, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[46], line 1\u001b[0;36m\u001b[0m\n\u001b[0;31m    import importlib.util spec\u001b[0m\n\u001b[0m                          ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import importlib.util spec\n",
    "import_file = importlib.util.spec_from_file_location(\"tutorials/ml_workflows\", \"basic_components.py\")    \n",
    "# arguments shared are \n",
    "file2=importlib.util.module_from_spec(import_file)        \n",
    "spec.loader.exec_module(file2)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1f58f406",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (771939628.py, line 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[36], line 4\u001b[0;36m\u001b[0m\n\u001b[0;31m    from Tutorials.Ml-Workflows.Basic_components import MyDataGetter, MyDatasetSplitter, MyTrainer\u001b[0m\n\u001b[0m                     ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "from itwinai.pipeline import Pipeline\n",
    "\n",
    "# Import the custom components from file\n",
    "from tubasic_components import MyDataGetter, MyDatasetSplitter, MyTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "53359cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load tutorials/ml-workflows/basic_components.py\n",
    "\"\"\"\n",
    "Here we show how to implement component interfaces in a simple way.\n",
    "\"\"\"\n",
    "from typing import List, Optional, Tuple, Any\n",
    "from itwinai.components import (\n",
    "    DataGetter, DataSplitter, Trainer, Saver, monitor_exec\n",
    ")\n",
    "\n",
    "\n",
    "class MyDataGetter(DataGetter):\n",
    "    def __init__(self, data_size: int, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.data_size = data_size\n",
    "        self.save_parameters(data_size=data_size)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(self) -> List[int]:\n",
    "        \"\"\"Return a list dataset.\n",
    "\n",
    "        Returns:\n",
    "            List[int]: dataset\n",
    "        \"\"\"\n",
    "        return list(range(self.data_size))\n",
    "\n",
    "\n",
    "class MyDatasetSplitter(DataSplitter):\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        dataset: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int]]:\n",
    "        \"\"\"Splits a list dataset into train, validation and test datasets.\n",
    "\n",
    "        Args:\n",
    "            dataset (List[int]): input list dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int]]: train, validation, and\n",
    "            test datasets.\n",
    "        \"\"\"\n",
    "        train_n = int(len(dataset)*self.train_proportion)\n",
    "        valid_n = int(len(dataset)*self.validation_proportion)\n",
    "        train_set = dataset[:train_n]\n",
    "        vaild_set = dataset[train_n:train_n+valid_n]\n",
    "        test_set = dataset[train_n+valid_n:]\n",
    "        return train_set, vaild_set, test_set\n",
    "\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, lr: float = 1e-3, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.save_parameters(name=name, lr=lr)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        train_set: List[int],\n",
    "        vaild_set: List[int],\n",
    "        test_set: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int], str]:\n",
    "        \"\"\"Dummy ML trainer mocking a ML training algorithm.\n",
    "\n",
    "        Args:\n",
    "            train_set (List[int]): training dataset.\n",
    "            vaild_set (List[int]): validation dataset.\n",
    "            test_set (List[int]): test dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int], str]: train, validation,\n",
    "            test datasets, and trained model.\n",
    "        \"\"\"\n",
    "        return train_set, vaild_set, test_set, \"my_trained_model\"\n",
    "\n",
    "\n",
    "class MySaver(Saver):\n",
    "    @monitor_exec\n",
    "    def execute(self, artifact: Any) -> Any:\n",
    "        \"\"\"Saves an artifact to disk.\n",
    "\n",
    "        Args:\n",
    "            artifact (Any): artifact to save (e.g., dataset, model).\n",
    "\n",
    "        Returns:\n",
    "            Any: input artifact.\n",
    "        \"\"\"\n",
    "        return artifact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a9497e1c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'basic_components'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[28], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mitwinai\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpipeline\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Pipeline\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import the custom components from file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic_components\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MyDataGetter, MyDatasetSplitter, MyTrainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'basic_components'"
     ]
    }
   ],
   "source": [
    "\n",
    "from itwinai.pipeline import Pipeline\n",
    "\n",
    "# Import the custom components from file\n",
    "from basic_components import MyDataGetter, MyDatasetSplitter, MyTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8870ee18",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'basic_components'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[26], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtutorials/ml-workflows/basic_components.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import the custom components from file\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic_components\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MyDataGetter, MyDatasetSplitter, MyTrainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'basic_components'"
     ]
    }
   ],
   "source": [
    "# %load tutorials/ml-workflows/basic_components.py\n",
    "\"\"\"\n",
    "Here we show how to implement component interfaces in a simple way.\n",
    "\"\"\"\n",
    "from typing import List, Optional, Tuple, Any\n",
    "from itwinai.components import (\n",
    "    DataGetter, DataSplitter, Trainer, Saver, monitor_exec\n",
    ")\n",
    "\n",
    "\n",
    "class MyDataGetter(DataGetter):\n",
    "    def __init__(self, data_size: int, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.data_size = data_size\n",
    "        self.save_parameters(data_size=data_size)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(self) -> List[int]:\n",
    "        \"\"\"Return a list dataset.\n",
    "\n",
    "        Returns:\n",
    "            List[int]: dataset\n",
    "        \"\"\"\n",
    "        return list(range(self.data_size))\n",
    "\n",
    "\n",
    "class MyDatasetSplitter(DataSplitter):\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        dataset: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int]]:\n",
    "        \"\"\"Splits a list dataset into train, validation and test datasets.\n",
    "\n",
    "        Args:\n",
    "            dataset (List[int]): input list dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int]]: train, validation, and\n",
    "            test datasets.\n",
    "        \"\"\"\n",
    "        train_n = int(len(dataset)*self.train_proportion)\n",
    "        valid_n = int(len(dataset)*self.validation_proportion)\n",
    "        train_set = dataset[:train_n]\n",
    "        vaild_set = dataset[train_n:train_n+valid_n]\n",
    "        test_set = dataset[train_n+valid_n:]\n",
    "        return train_set, vaild_set, test_set\n",
    "\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, lr: float = 1e-3, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.save_parameters(name=name, lr=lr)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        train_set: List[int],\n",
    "        vaild_set: List[int],\n",
    "        test_set: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int], str]:\n",
    "        \"\"\"Dummy ML trainer mocking a ML training algorithm.\n",
    "\n",
    "        Args:\n",
    "            train_set (List[int]): training dataset.\n",
    "            vaild_set (List[int]): validation dataset.\n",
    "            test_set (List[int]): test dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int], str]: train, validation,\n",
    "            test datasets, and trained model.\n",
    "        \"\"\"\n",
    "        return train_set, vaild_set, test_set, \"my_trained_model\"\n",
    "\n",
    "\n",
    "class MySaver(Saver):\n",
    "    @monitor_exec\n",
    "    def execute(self, artifact: Any) -> Any:\n",
    "        \"\"\"Saves an artifact to disk.\n",
    "\n",
    "        Args:\n",
    "            artifact (Any): artifact to save (e.g., dataset, model).\n",
    "\n",
    "        Returns:\n",
    "            Any: input artifact.\n",
    "        \"\"\"\n",
    "        return artifact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "eabefa6d",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'basic_components'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import the custom components from file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtutorials/ml-workflows/basic_components.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic_components\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MyDataGetter, MyDatasetSplitter, MyTrainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'basic_components'"
     ]
    }
   ],
   "source": [
    "# %load tutorials/ml-workflows/basic_components.py\n",
    "\"\"\"\n",
    "Here we show how to implement component interfaces in a simple way.\n",
    "\"\"\"\n",
    "from typing import List, Optional, Tuple, Any\n",
    "from itwinai.components import (\n",
    "    DataGetter, DataSplitter, Trainer, Saver, monitor_exec\n",
    ")\n",
    "\n",
    "\n",
    "class MyDataGetter(DataGetter):\n",
    "    def __init__(self, data_size: int, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.data_size = data_size\n",
    "        self.save_parameters(data_size=data_size)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(self) -> List[int]:\n",
    "        \"\"\"Return a list dataset.\n",
    "\n",
    "        Returns:\n",
    "            List[int]: dataset\n",
    "        \"\"\"\n",
    "        return list(range(self.data_size))\n",
    "\n",
    "\n",
    "class MyDatasetSplitter(DataSplitter):\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        dataset: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int]]:\n",
    "        \"\"\"Splits a list dataset into train, validation and test datasets.\n",
    "\n",
    "        Args:\n",
    "            dataset (List[int]): input list dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int]]: train, validation, and\n",
    "            test datasets.\n",
    "        \"\"\"\n",
    "        train_n = int(len(dataset)*self.train_proportion)\n",
    "        valid_n = int(len(dataset)*self.validation_proportion)\n",
    "        train_set = dataset[:train_n]\n",
    "        vaild_set = dataset[train_n:train_n+valid_n]\n",
    "        test_set = dataset[train_n+valid_n:]\n",
    "        return train_set, vaild_set, test_set\n",
    "\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, lr: float = 1e-3, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.save_parameters(name=name, lr=lr)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        train_set: List[int],\n",
    "        vaild_set: List[int],\n",
    "        test_set: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int], str]:\n",
    "        \"\"\"Dummy ML trainer mocking a ML training algorithm.\n",
    "\n",
    "        Args:\n",
    "            train_set (List[int]): training dataset.\n",
    "            vaild_set (List[int]): validation dataset.\n",
    "            test_set (List[int]): test dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int], str]: train, validation,\n",
    "            test datasets, and trained model.\n",
    "        \"\"\"\n",
    "        return train_set, vaild_set, test_set, \"my_trained_model\"\n",
    "\n",
    "\n",
    "class MySaver(Saver):\n",
    "    @monitor_exec\n",
    "    def execute(self, artifact: Any) -> Any:\n",
    "        \"\"\"Saves an artifact to disk.\n",
    "\n",
    "        Args:\n",
    "            artifact (Any): artifact to save (e.g., dataset, model).\n",
    "\n",
    "        Returns:\n",
    "            Any: input artifact.\n",
    "        \"\"\"\n",
    "        return artifact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "93fa18ce",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'basic_components'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 5\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Import the custom components from file\u001b[39;00m\n\u001b[1;32m      4\u001b[0m get_ipython()\u001b[38;5;241m.\u001b[39mrun_line_magic(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mload\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtutorials/ml-workflows/basic_components.py\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mbasic_components\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MyDataGetter, MyDatasetSplitter, MyTrainer\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'basic_components'"
     ]
    }
   ],
   "source": [
    "\n",
    "\"\"\"\n",
    "Here we show how to implement component interfaces in a simple way.\n",
    "\"\"\"\n",
    "from typing import List, Optional, Tuple, Any\n",
    "from itwinai.components import (\n",
    "    DataGetter, DataSplitter, Trainer, Saver, monitor_exec\n",
    ")\n",
    "\n",
    "\n",
    "class MyDataGetter(DataGetter):\n",
    "    def __init__(self, data_size: int, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.data_size = data_size\n",
    "        self.save_parameters(data_size=data_size)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(self) -> List[int]:\n",
    "        \"\"\"Return a list dataset.\n",
    "\n",
    "        Returns:\n",
    "            List[int]: dataset\n",
    "        \"\"\"\n",
    "        return list(range(self.data_size))\n",
    "\n",
    "\n",
    "class MyDatasetSplitter(DataSplitter):\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        dataset: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int]]:\n",
    "        \"\"\"Splits a list dataset into train, validation and test datasets.\n",
    "\n",
    "        Args:\n",
    "            dataset (List[int]): input list dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int]]: train, validation, and\n",
    "            test datasets.\n",
    "        \"\"\"\n",
    "        train_n = int(len(dataset)*self.train_proportion)\n",
    "        valid_n = int(len(dataset)*self.validation_proportion)\n",
    "        train_set = dataset[:train_n]\n",
    "        vaild_set = dataset[train_n:train_n+valid_n]\n",
    "        test_set = dataset[train_n+valid_n:]\n",
    "        return train_set, vaild_set, test_set\n",
    "\n",
    "\n",
    "class MyTrainer(Trainer):\n",
    "    def __init__(self, lr: float = 1e-3, name: Optional[str] = None) -> None:\n",
    "        super().__init__(name)\n",
    "        self.save_parameters(name=name, lr=lr)\n",
    "\n",
    "    @monitor_exec\n",
    "    def execute(\n",
    "        self,\n",
    "        train_set: List[int],\n",
    "        vaild_set: List[int],\n",
    "        test_set: List[int]\n",
    "    ) -> Tuple[List[int], List[int], List[int], str]:\n",
    "        \"\"\"Dummy ML trainer mocking a ML training algorithm.\n",
    "\n",
    "        Args:\n",
    "            train_set (List[int]): training dataset.\n",
    "            vaild_set (List[int]): validation dataset.\n",
    "            test_set (List[int]): test dataset.\n",
    "\n",
    "        Returns:\n",
    "            Tuple[List[int], List[int], List[int], str]: train, validation,\n",
    "            test datasets, and trained model.\n",
    "        \"\"\"\n",
    "        return train_set, vaild_set, test_set, \"my_trained_model\"\n",
    "\n",
    "\n",
    "class MySaver(Saver):\n",
    "    @monitor_exec\n",
    "    def execute(self, artifact: Any) -> Any:\n",
    "        \"\"\"Saves an artifact to disk.\n",
    "\n",
    "        Args:\n",
    "            artifact (Any): artifact to save (e.g., dataset, model).\n",
    "\n",
    "        Returns:\n",
    "            Any: input artifact.\n",
    "        \"\"\"\n",
    "        return artifact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "227cd1e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    # Assemble them in a scikit-learn like pipeline\n",
    "    pipeline = Pipeline([\n",
    "        MyDataGetter(data_size=100),\n",
    "        MyDatasetSplitter(\n",
    "            train_proportion=.5,\n",
    "            validation_proportion=.25,\n",
    "            test_proportion=0.25\n",
    "        ),\n",
    "        MyTrainer()\n",
    "    ])\n",
    "\n",
    "    # Inspect steps\n",
    "    print(pipeline[0])\n",
    "    print(pipeline[2].name)\n",
    "    print(pipeline[1].train_proportion)\n",
    "\n",
    "    # Run pipeline\n",
    "    _, _, _, trained_model = pipeline.execute()\n",
    "    print(\"Trained model: \", trained_model)\n",
    "\n",
    "    # You can also create a Pipeline from a dict of components, which\n",
    "    # simplifies their retrieval by name\n",
    "    pipeline = Pipeline({\n",
    "        \"datagetter\": MyDataGetter(data_size=100),\n",
    "        \"splitter\": MyDatasetSplitter(\n",
    "            train_proportion=.5,\n",
    "            validation_proportion=.25,\n",
    "            test_proportion=0.25\n",
    "        ),\n",
    "        \"trainer\": MyTrainer()\n",
    "    })\n",
    "\n",
    "    # Inspect steps\n",
    "    print(pipeline[\"datagetter\"])\n",
    "    print(pipeline[\"trainer\"].name)\n",
    "    print(pipeline[\"splitter\"].train_proportion)\n",
    "\n",
    "    # Run pipeline\n",
    "    _, _, _, trained_model = pipeline.execute()\n",
    "    print(\"Trained model: \", trained_model)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
