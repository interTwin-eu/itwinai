{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing Libraries and Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tqdm.notebook import tqdm "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Path Initialization\n",
    "\n",
    "This cell initializes the paths to the dataset and the models.\n",
    "\n",
    "+ `PATH_DATASET` is the directory where the synthetic data is saved.\n",
    "+ `PATH_SET` is the complete path to the test dataset file within the dataset directory.\n",
    "+ `PATH_MODELS` is the directory where the model files are located."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH_DATASET = '../../2_training/data/datasets/'\n",
    "PATH_SET = f'{PATH_DATASET}test_dataset.npy'\n",
    "PATH_MODELS = '../models/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Files Retrieval\n",
    "\n",
    "This cell retrieves the list of all model files located in the PATH_MODELS directory. The glob function is used to get all files with the .h5 extension, representing the saved model files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = glob.glob(f'{PATH_MODELS}*.keras')\n",
    "models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Loading\n",
    "\n",
    "This cell loads the test dataset from the PATH_SET into the variable dataset. The dataset is expanded along a new axis to match the input shape required by the models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = np.load(PATH_SET)[..., tf.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Loading and Prediction\n",
    "\n",
    "In this cell, each `model` in the `models` list is loaded and used to predict the labels of the instances in the dataset. For each model, a new DataFrame `table_labels` is created to store the index (subint) and the predicted label (`models_label`) for each instance in the dataset. After predicting labels for all instances in the dataset with a model, the corresponding `table_labels` DataFrame is saved as a CSV file, with the filename indicating which model was used for prediction. The tqdm is used here to display progress bars for model loading and label prediction processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for model in tqdm(models):\n",
    "    loaded_model = tf.keras.models.load_model(model)\n",
    "    table_labels = pd.DataFrame(columns=['subint', 'models_label'])\n",
    "    for idx, image in enumerate(tqdm(dataset)):\n",
    "        image = tf.expand_dims(image, 0)\n",
    "        model_prediction = loaded_model.predict(image)\n",
    "        label = np.argmax(model_prediction)\n",
    "        table_labels.loc[idx] = [\n",
    "            idx, \n",
    "            label\n",
    "        ]\n",
    "    \n",
    "    table_labels.to_csv(f'../models_labels/labels_real_data_by_{os.path.basename(model).split(\".\")[0]}.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
