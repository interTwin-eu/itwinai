root_folder: /p/scratch/intertwin/datasets/virgo
data_root: ./data
epochs: 2
batch_size: 3
learning_rate: 0.0001
strategy: deepspeed
checkpoint_path: checkpoints/epoch_{}.pth

# To use the entire synthetic dataset that is generated prior to running the pipeline
training_pipeline:
  class_path: itwinai.pipeline.Pipeline
  init_args:
    steps:
      - class_path: data.TimeSeriesDatasetSplitter
        init_args:
          train_proportion: 0.9
          validation_proportion: 0.1
          rnd_seed: 42
          root_folder: ${root_folder}
      - class_path: trainer.NoiseGeneratorTrainer
        init_args:
          config:
            generator: simple #unet
            batch_size: ${batch_size}
            optim_lr: ${learning_rate}
            loss: L1
            save_best: true
            shuffle_train: true
          num_epochs: ${epochs}
          strategy: ${strategy}
          checkpoint_path: ${checkpoint_path}
          random_seed: 17
          validation_every: 0
          logger:
            class_path: itwinai.loggers.LoggersCollection
            init_args:
              loggers:
                - class_path: itwinai.loggers.ConsoleLogger
                  init_args:
                    log_freq: 1
                - class_path: itwinai.loggers.MLFlowLogger
                  init_args:
                    experiment_name: Noise simulator (Virgo)
                    log_freq: batch 
       
          
# To use a small dataset that is generated within the pipeline
training_pipeline_small:
  class_path: itwinai.pipeline.Pipeline
  init_args:
    steps:
      - class_path: data.TimeSeriesDatasetGenerator
        init_args:
          data_root: ${data_root}
      - class_path: data.TimeSeriesDatasetSplitterSmall
        init_args:
          train_proportion: 0.9
          validation_proportion: 0.1
          rnd_seed: 42
      - class_path: data.TimeSeriesProcessorSmall          
      - class_path: trainer.NoiseGeneratorTrainer
        init_args:
        config:
            generator: simple #unet
            batch_size: ${batch_size}
            optim_lr: ${learning_rate}
            loss: L1
            save_best: true
            shuffle_train: true
        num_epochs: ${epochs}
        strategy: ${strategy}
        checkpoint_path: ${checkpoint_path}
        random_seed: 17
        validation_every: 0
        logger:
          class_path: itwinai.loggers.LoggersCollection
          init_args:
            loggers:
              - class_path: itwinai.loggers.ConsoleLogger
                init_args:
                  log_freq: 1
              - class_path: itwinai.loggers.MLFlowLogger
                init_args:
                  experiment_name: Noise simulator (Virgo)
                  log_freq: batch 
      

# To use the entire synthetic dataset that is generated prior to running the pipeline
ray_training_pipeline:
  class_path: itwinai.pipeline.Pipeline
  init_args:
    steps:
      - class_path: data.TimeSeriesDatasetSplitter
        init_args:
          train_proportion: 0.9
          validation_proportion: 0.1
          rnd_seed: 42
          root_folder: ${root_folder}
      - class_path: trainer.RayNoiseGeneratorTrainer
        init_args:
          config:
            scaling_config:
                num_workers: 2
                use_gpu: true
                resources_per_worker:
                  CPU: 5
                  GPU: 1
            tune_config:
              num_samples: 2
              # scheduler:
              #   name: asha
              #   max_t: 10
              #   grace_period: 5
              #   reduction_factor: 4
              #   brackets: 1
            run_config:
              storage_path: ray_checkpoints
              name: Virgo-HPO-Experiment
            train_loop_config:
              batch_size: 
                type: choice
                options: [32, 64, 128]
              learning_rate:
                type: uniform
                min: 1e-5
                max: 1e-3
              epochs: 2
              generator: simple #unet
              loss: L1
              save_best: false
              shuffle_train: true
              random_seed: 17
              tracking_uri: mllogs/mlflow
              experiment_name: Virgo-HPO-Experiment
          strategy: ${strategy}
          logger:
            class_path: itwinai.loggers.LoggersCollection
            init_args:
              loggers:
                - class_path: itwinai.loggers.MLFlowLogger
                  init_args:
                    experiment_name: MNIST Ray HPO Experiment
                    log_freq: batch 

                
          
          
# To use a small dataset that is generated within the pipeline
ray_training_pipeline_small:
  class_path: itwinai.pipeline.Pipeline
  init_args:
    steps:
      - class_path: data.TimeSeriesDatasetGenerator
        init_args:
          data_root: ${data_root}
      - class_path: data.TimeSeriesDatasetSplitterSmall
        init_args:
          train_proportion: 0.9
          validation_proportion: 0.1
          rnd_seed: 42
      - class_path: data.TimeSeriesProcessorSmall          
      - class_path: trainer.RayNoiseGeneratorTrainer
        init_args:
          config:
            scaling_config:
                num_workers: 2
                use_gpu: true
                resources_per_worker:
                  CPU: 5
                  GPU: 1
            tune_config:
              num_samples: 4
              scheduler:
                name: asha
                max_t: 10
                grace_period: 5
                reduction_factor: 4
                brackets: 1
            run_config:
              storage_path: ray_checkpoints
              name: Virgo-HPO-Experiment
            train_loop_config:
              batch_size: 
                type: choice
                options: [32, 64, 128]
              learning_rate:
                type: uniform
                min: 1e-5
                max: 1e-3
              epochs: 10
              generator: simple #unet
              loss: L1
              save_best: false
              shuffle_train: true
              random_seed: 17
              tracking_uri: mllogs/mlflow
              experiment_name: Virgo-HPO-Experiment
          strategy: ${strategy}
          logger:
            class_path: itwinai.loggers.LoggersCollection
            init_args:
              loggers:
                - class_path: itwinai.loggers.MLFlowLogger
                  init_args:
                    experiment_name: Virgo Ray HPO Experiment
                    log_freq: batch 
