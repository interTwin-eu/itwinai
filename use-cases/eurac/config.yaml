# --------------------------------------------------------------------------------------
# Part of the interTwin Project: https://www.intertwin.eu/
#
# Created by: Matteo Bunino
#
# Credit:
# - Jarl Sondre SÃ¦ther <jarl.sondre.saether@cern.ch> - CERN
# - Henry Mutegeki <henry.mutegeki@cern.ch> - CERN
# - Iacopo Ferrario <iacopofederico.ferrario@eurac.edu> - EURAC
# - Matteo Bunino <matteo.bunino@cern.ch> - CERN
# --------------------------------------------------------------------------------------

# General configuration
experiment_name: "itwinai"
experiment_run: "vwc_actevap"

work_dir: /p/scratch/intertwin/datasets/eurac/model
dataset_root: /p/scratch/intertwin/datasets/eurac/input

train_temporal_range: ["2016-01-01", "2018-12-31"]
valid_temporal_range: ["2019-01-01", "2020-12-31"]
test_temporal_range: ["2019-01-01", "2020-12-31"]

seed: 1000

device: "cuda:0"

# === Model ===

model_file_name: model.pt

model: cudalstm

hidden_size: 136
dropout: 0.4

model_head_layer: regression # distr_normal
model_head_activation: linear
model_head_kwargs: null

# === Training ===

strategy: ddp #null

hython_trainer: rnntrainer

loss_fn:
  _target_: hython.losses.RMSELoss

# metric_fn:
#   _target_: hython.metrics.MSEMetric

metric_fn:
  _target_: hython.metrics.MetricCollection
  metrics:
    # - _target_: hython.metrics.MSEMetric
    - _target_: hython.metrics.KGEMetric
    - _target_: hython.metrics.NSEMetric

optimizer: adam

lr_scheduler:
  mode: min
  factor: 0.5
  patience: 10

seq_length: 120

learning_rate: 0.001

batch: 256

epochs: 40

gradient_clip: null

target_weights: even # null, even, or dict

# which steps are used in the computation of the loss function
predict_steps: 0 # all # (prediction: 0 = t ), ( forecasts: 1 = t+1, 2 = t + 2)

# > Donwsampling <

interval_value: 5
# spatial downsampling
train_downsampler:
  _target_: hython.sampler.downsampler.RegularIntervalDownsampler
  intervals:
    - ${interval_value}
    - ${interval_value}
  origin: [0, 0]

valid_downsampler:
  _target_: hython.sampler.downsampler.RegularIntervalDownsampler
  intervals:
    - ${interval_value}
    - ${interval_value}
  origin: [1, 1]

test_downsampler:
  _target_: hython.sampler.downsampler.RegularIntervalDownsampler
  intervals:
    - ${interval_value}
    - ${interval_value}
  origin: [2, 2]

# temporal downsampling
temporal_downsampling: True
temporal_subset: [200, 150]

# === Data ===

dataset: Wflow1d

data_source:
  file:
    data_dir: ${dataset_root}
    data_file: alps1km_eobs_preprocessed.zarr
  # s3:
  #   url: https://eurac-eo.s3.amazonaws.com/INTERTWIN/SURROGATE_INPUT/adg1km_eobs_preprocessed.zarr/

static_categorical_inputs:
  - wflow_landuse
  - wflow_soil

static_inputs:
  - thetaS
  - thetaR
  - KsatVer
  - c
  - f
  - RootingDepth
  - Swood
  - Kext
  - Sl

dynamic_inputs:
  - precip
  - pet
  - temp

target_variables:
  - vwc
  - actevap
  - swe

mask_variables:
  - mask_missing
  - mask_lake

# Scaling

scaling_variant: minmax
scaling_use_cached: True

# == Pipeline ==

training_pipeline:
  _target_: itwinai.pipeline.Pipeline
  steps:
    - _target_: data.RNNDatasetGetterAndPreprocessor
      dynamic_inputs: ${dynamic_inputs}
      static_inputs: ${static_inputs}
      target_variables: ${target_variables}
      mask_variables: ${mask_variables}
      train_temporal_range: ${train_temporal_range}
      valid_temporal_range: ${valid_temporal_range}
      dataset: ${dataset}
      data_source: ${data_source}
      scaling_variant: ${scaling_variant}
      scaling_use_cached: ${scaling_use_cached}
      experiment_name: ${experiment_name}
      experiment_run: ${experiment_run}
      work_dir: ${work_dir}
      train_downsampler: ${train_downsampler}
      valid_downsampler: ${valid_downsampler}
    - _target_: trainer.RNNDistributedTrainer
      model: ${model}
      config:
        experiment: ${experiment_name}/${experiment_run}
        experiment_name: ${experiment_name}
        experiment_run: ${experiment_run}
        work_dir: ${work_dir}
        batch_size: ${batch}
        learning_rate: ${learning_rate}
        num_workers_dataloader: 1
        hython_trainer: ${hython_trainer}
        temporal_downsampling: ${temporal_downsampling}
        temporal_subset: ${temporal_subset}
        seq_length: ${seq_length}
        target_variables: ${target_variables}
        dynamic_inputs: ${dynamic_inputs}
        static_inputs: ${static_inputs}

        optimizer: ${optimizer}
        lr_scheduler: ${lr_scheduler}
        target_weights: ${target_weights}

        # model config
        model_file_name: ${model_file_name}
        hidden_size: ${hidden_size}
        dropout: ${dropout}

        model_head_layer: ${model_head_layer}
        model_head_activation: ${model_head_activation}
        model_head_kwargs: ${model_head_kwargs}

        loss_fn: ${loss_fn}
        metric_fn: ${metric_fn}

        gradient_clip: ${gradient_clip}

        predict_steps: ${predict_steps}

      strategy: ddp
      epochs: ${epochs}
      random_seed: ${seed}
      #profiling_wait_epochs: 1
      #profiling_warmup_epochs: 1
      logger:
        _target_: itwinai.loggers.LoggersCollection
        loggers:
          - _target_: itwinai.loggers.ConsoleLogger
            log_freq: 100
          - _target_: itwinai.loggers.MLFlowLogger
            experiment_name: Eurac HPO Experiment Baseline
            # run_name: ${experiment_run}
            log_freq: epoch

ray_training_pipeline:
  _target_: itwinai.pipeline.Pipeline
  steps:
    - _target_: data.RNNDatasetGetterAndPreprocessor
      dynamic_inputs: ${dynamic_inputs}
      static_inputs: ${static_inputs}
      target_variables: ${target_variables}
      mask_variables: ${mask_variables}
      train_temporal_range: ${train_temporal_range}
      valid_temporal_range: ${valid_temporal_range}
      dataset: ${dataset}
      data_source: ${data_source}
      scaling_variant: ${scaling_variant}
      scaling_use_cached: ${scaling_use_cached}
      experiment_name: ${experiment_name}
      experiment_run: ${experiment_run}
      work_dir: ${work_dir}
      train_downsampler: ${train_downsampler}
      valid_downsampler: ${valid_downsampler}

    - _target_: trainer.RNNDistributedRayTrainer
      model: ${model}
      config:
        experiment: ${experiment_name}/${experiment_run}
        experiment_name: ${experiment_name}
        experiment_run: ${experiment_run}
        work_dir: ${work_dir}

        num_workers_dataloader: 1
        hython_trainer: ${hython_trainer}
        temporal_downsampling: ${temporal_downsampling}
        temporal_subset: ${temporal_subset}
        seq_length: ${seq_length}
        target_variables: ${target_variables}
        dynamic_inputs: ${dynamic_inputs}
        static_inputs: ${static_inputs}

        optimizer: ${optimizer}
        lr_scheduler: ${lr_scheduler}
        target_weights: ${target_weights}

        # model config
        model_file_name: ${model_file_name}
        hidden_size: ${hidden_size}
        dropout: ${dropout}

        model_head_layer: ${model_head_layer}
        model_head_activation: ${model_head_activation}
        model_head_kwargs: ${model_head_kwargs}

        loss_fn: ${loss_fn}
        metric_fn: ${metric_fn}
        gradient_clip: ${gradient_clip}
        predict_steps: ${predict_steps}

        train_loop_config:
          learning_rate:
            type: uniform
            lower: 1e-5
            upper: 1e-3

          batch:
            type: choice
            categories: [64, 128, 256]

        scaling_config:
          num_workers: 2
          use_gpu: true
          resources_per_worker:
            CPU: 5
            GPU: 1

        tune_config:
          num_samples: 2
          # scheduler:
          #   name: asha
          #   max_t: 5
          #   grace_period: 2
          #   reduction_factor: 6
          #   brackets: 1

        run_config:
          storage_path: ray_checkpoints
          name: Eurac-HPO-Experiment

      strategy: ${strategy}
      epochs: ${epochs}
      random_seed: ${seed}
      #profiling_wait_epochs: 1
      #profiling_warmup_epochs: 1
      logger:
        _target_: itwinai.loggers.LoggersCollection
        loggers:
          - _target_: itwinai.loggers.ConsoleLogger
            log_freq: 100
          - _target_: itwinai.loggers.MLFlowLogger
            experiment_name: Distributed Eurac HPO Experiment
            # run_name: ${experiment_run}
            log_freq: epoch
            savedir: mllogs/mlflow
