# --------------------------------------------------------------------------------------
# Part of the interTwin Project: https://www.intertwin.eu/
#
# Created by: Matteo Bunino
#
# Credit:
# - Matteo Bunino <matteo.bunino@cern.ch> - CERN
# - Anna Lappe <anna.elisa.lappe@cern.ch> - CERN
# --------------------------------------------------------------------------------------

# General config
dataset_root: .tmp/

training_pipeline:
  _target_: itwinai.pipeline.Pipeline
  steps:
    - _target_: dataloader.LightningMNISTDownloader
      data_path: ${dataset_root}

    - _target_: itwinai.torch.trainer.TorchLightningTrainer
      config:
        # Pytorch lightning config for training
        seed_everything: 4231162351
        trainer:
          accelerator: auto
          accumulate_grad_batches: 1
          barebones: false
          callbacks:
            - _target_: lightning.pytorch.callbacks.early_stopping.EarlyStopping
              monitor: val_loss
              patience: 2
            - _target_: lightning.pytorch.callbacks.lr_monitor.LearningRateMonitor
              logging_interval: step
            - _target_: lightning.pytorch.callbacks.ModelCheckpoint
              dirpath: checkpoints
              filename: best-checkpoint
              mode: min
              monitor: val_loss
              save_top_k: 1
              verbose: true
          check_val_every_n_epoch: 1
          default_root_dir: null
          detect_anomaly: false
          deterministic: null
          devices: auto
          enable_checkpointing: null
          enable_model_summary: null
          enable_progress_bar: null
          fast_dev_run: false
          gradient_clip_algorithm: null
          gradient_clip_val: null
          inference_mode: true
          limit_predict_batches: null
          limit_test_batches: null
          limit_train_batches: null
          limit_val_batches: null
          log_every_n_steps: null
          logger:
            class_path: itwinai.torch.loggers.ItwinaiLogger
            init_args:
              log_model: all
              itwinai_logger:
                class_path: itwinai.loggers.MLFlowLogger
                init_args:
                  savedir: mllogs
          max_epochs: 2
          max_steps: -1
          max_time: null
          min_epochs: null
          min_steps: null
          num_sanity_val_steps: null
          overfit_batches: 0.0
          plugins: null
          profiler: null
          reload_dataloaders_every_n_epochs: 0
          strategy: auto
          sync_batchnorm: false
          use_distributed_sampler: true
          val_check_interval: null

        # Lightning Model configuration
        model:
          _target_: itwinai.torch.models.mnist.MNISTModel
          hidden_size: 64

        # Lightning data module configuration
        data:
          _target_: dataloader.MNISTDataModule
          batch_size: 32
          data_path: ${dataset_root}
          download: false
          train_prop: 0.8

        # Torch Optimizer configuration
        optimizer:
          class_path: torch.optim.AdamW
          init_args:
            lr: 0.001

        # Torch LR scheduler configuration
        lr_scheduler:
          class_path: torch.optim.lr_scheduler.ExponentialLR
          init_args:
            gamma: 0.1
