job_name: my_slurm_job
account: intertwin
dist_strat: ddp
time: 00:11:11

num_nodes: 1
num_tasks_per_node: 1
gpus_per_node: 4
cpus_per_task: 16

# Keep in mind that these will be overwritten if "mode" is not "single", and that
# if you override the dist_strat in the CLI, then these will already have evaluated
# and thus might not correspond. Thus, we suggest you only change the dist_strat in
# the config and avoid overriding it in the CLI.
std_out: slurm_job_logs/${dist_strat}-${num_nodes}x${gpus_per_node}.out
err_out: slurm_job_logs/${dist_strat}-${num_nodes}x${gpus_per_node}.err

python_venv: .venv

# Make sure the below strategy matches the one above
training_cmd: | 
  $(which itwinai) exec-pipeline \
  --config config.yaml \
  --pipe-key rnn_training_pipeline \
  -o strategy={dist_strat}
